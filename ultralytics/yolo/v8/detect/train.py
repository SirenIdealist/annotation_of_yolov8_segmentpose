# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# æµ…æ‹·è´ï¼Œç”¨äºå¤åˆ¶ argsï¼ˆé¿å…åŸå¯¹è±¡è¢«ä¸‹æ¸¸ä¿®æ”¹ï¼‰
from copy import copy

# ä»…ç”¨äº plot_training_labels èšåˆæ ‡ç­¾
import numpy as np

# ä»»åŠ¡çº§æ¨¡å‹æ„å»ºç±»ï¼ˆå°è£… backbone+neck+headï¼‰
from ultralytics.nn.tasks import DetectionModel
# è®¿é—®å­æ¨¡å— registerï¼ˆå¦‚ v8.detect.DetectionValidatorï¼‰
from ultralytics.yolo import v8
# æ•°æ®ç›¸å…³å¯¼å…¥ï¼šæä¾›å®˜æ–¹æ–°æ•°æ®ç®¡çº¿ä¸å…¼å®¹æ—§ç‰ˆ v5loader çš„å…¥å£
from ultralytics.yolo.data import build_dataloader, build_yolo_dataset
from ultralytics.yolo.data.dataloaders.v5loader import create_dataloader
# é€šç”¨è®­ç»ƒå¾ªç¯åŸºç±»BaseTrainerï¼ˆä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€æ—¥å¿—ã€DDPã€EMA ç­‰ï¼‰
from ultralytics.yolo.engine.trainer import BaseTrainer
# é»˜è®¤é…ç½®å¯¹è±¡ï¼›æ—¥å¿—è®°å½•å™¨ï¼›åˆ†å¸ƒå¼ rankï¼›å½©è‰²å­—ç¬¦ä¸²å·¥å…·
from ultralytics.yolo.utils import DEFAULT_CFG, LOGGER, RANK, colorstr
from ultralytics.yolo.utils.plotting import plot_images, plot_labels, plot_results
# å¤„ç†å¹¶è¡Œæ¨¡å‹ï¼ˆæ‹¿çœŸå® moduleï¼‰ï¼›åˆ†å¸ƒå¼ç¯å¢ƒä¸­åªåœ¨ rank0 åˆå§‹åŒ–ç¼“å­˜
from ultralytics.yolo.utils.torch_utils import de_parallel, torch_distributed_zero_first


# BaseTrainer python usage
class DetectionTrainer(BaseTrainer):

    def build_dataset(self, img_path, mode='train', batch=None):
        """Build YOLO Dataset

        Args:
            img_path (str): Path to the folder containing images.
            mode (str): `train` mode or `val` mode, users are able to customize different augmentations for each mode.
            batch (int, optional): Size of batches, this is for `rect`. Defaults to None.
        """
        # è·å– strideï¼šæ¨¡å‹æœ‰è‹¥å¹²è¾“å‡ºå±‚ï¼Œå¯¹åº”æ­¥å¹…ï¼›å–æœ€å¤§ stride ä¿éšœ mosaic/rect è£å‰ªç¬¦åˆç½‘æ ¼ï¼›è‹¥æ¨¡å‹æœªæ„å»ºé»˜è®¤ 0 â†’ ç”¨ 32 ä½œä¿åº•
        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)
        # ä¾æ® argsï¼ˆå«å¢å¼ºã€imgszã€ç¼“å­˜ç­‰ï¼‰ã€æ•°æ®é›†é…ç½® self.dataï¼ˆè§£æ data.yamlï¼‰ã€æ¨¡å¼ train/valã€rectï¼ˆéªŒè¯é˜¶æ®µç”¨é•¿è¾¹ç­‰æ¯”çŸ©å½¢å¡«å……ï¼‰åˆ›å»º Dataset å¯¹è±¡ã€‚batch ä»…åœ¨ rect ç­–ç•¥ä¸‹å½±å“ aspect ratio bucketingã€‚
        return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == 'val', stride=gs)

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode='train'):
        """TODO: manage splits differently."""
        # Calculate stride - check if model is initialized
        if self.args.v5loader: # åˆ†æ”¯ä½¿ç”¨æ—§å¼ create_dataloaderï¼ˆå…¼å®¹ YOLOv5 é£æ ¼ï¼‰ã€‚å‘å‡º deprecated è­¦å‘Šã€‚
            LOGGER.warning("WARNING âš ï¸ 'v5loader' feature is deprecated and will be removed soon. You can train using "
                           'the default YOLOv8 dataloader instead, no argument is needed.')
            gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)
            return create_dataloader(path=dataset_path,
                                     imgsz=self.args.imgsz,
                                     batch_size=batch_size,
                                     stride=gs,
                                     hyp=vars(self.args),
                                     augment=mode == 'train',
                                     cache=self.args.cache,
                                     pad=0 if mode == 'train' else 0.5,
                                     rect=self.args.rect or mode == 'val',
                                     rank=rank,
                                     workers=self.args.workers,
                                     close_mosaic=self.args.close_mosaic != 0,
                                     prefix=colorstr(f'{mode}: '),
                                     shuffle=mode == 'train',
                                     seed=self.args.seed)[0]
        assert mode in ['train', 'val']
        with torch_distributed_zero_first(rank):  # init dataset *.cache only once if ï¼Œåªæœ‰ rank0 é¦–æ¬¡æ„å»ºï¼ˆå†™ç¼“å­˜ .cacheï¼‰ï¼Œå…¶ä½™ç­‰å¾… â†’ é™ä½å¤šè¿›ç¨‹ç«äº‰
            dataset = self.build_dataset(dataset_path, mode, batch_size)
        shuffle = mode == 'train'
        if getattr(dataset, 'rect', False) and shuffle:
            LOGGER.warning("WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False")
            shuffle = False
        workers = self.args.workers if mode == 'train' else self.args.workers * 2
        return build_dataloader(dataset, batch_size, workers, shuffle, rank)  # return dataloader

    def preprocess_batch(self, batch):
        """Preprocesses a batch of images by scaling and converting to float."""
        batch['img'] = batch['img'].to(self.device, non_blocking=True).float() / 255 # æŠŠ uint8 æˆ– half ç­‰è½¬ float32ï¼Œå¹¶å½’ä¸€åŒ–åˆ° [0,1]ã€‚ä¸åœ¨è¿™é‡Œåšå‡å€¼æ–¹å·®æ ‡å‡†åŒ–ï¼ˆYOLO ç³»åˆ—é€šå¸¸ç›´æ¥ 0-1ï¼‰
        return batch

    def set_model_attributes(self):
        """nl = de_parallel(self.model).model[-1].nl  # number of detection layers (to scale hyps)."""
        # self.args.box *= 3 / nl  # scale to layers
        # self.args.cls *= self.data["nc"] / 80 * 3 / nl  # scale to classes and layers
        # self.args.cls *= (self.args.imgsz / 640) ** 2 * 3 / nl  # scale to image size and layers
        self.model.nc = self.data['nc']  # attach number of classes to model
        self.model.names = self.data['names']  # attach class names to model
        self.model.args = self.args  # attach hyperparameters to model
        # TODO: self.model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc

    def get_model(self, cfg=None, weights=None, verbose=True):
        """Return a YOLO detection model."""
        # verbose åªåœ¨å•æœºä¸»è¿›ç¨‹æ‰“å°ç½‘ç»œç»“æ„ï¼ˆRANK==-1 è¡¨ç¤ºéåˆ†å¸ƒå¼æˆ–ä¸»ï¼‰
        # weights: è‹¥æŒ‡å®šé¢„è®­ç»ƒæƒé‡å† loadï¼ˆå†…éƒ¨æ‰§è¡Œ shape åŒ¹é…å¹¶å¿½ç•¥ä¸å…¼å®¹å±‚ï¼‰
        model = DetectionModel(cfg, nc=self.data['nc'], verbose=verbose and RANK == -1)
        if weights:
            model.load(weights)
        return model # è¿”å›å®ä¾‹ä¾›è®­ç»ƒ

    def get_validator(self):
        """Returns a DetectionValidator for YOLO model validation."""
        self.loss_names = 'box_loss', 'cls_loss', 'dfl_loss' # è®¾ç½®æŸå¤±åç§°ï¼šä¸ forward è¿”å›çš„ loss å¼ é‡é¡ºåºä¸€è‡´ï¼ˆbox å›å½’ã€åˆ†ç±»ã€dfl=Distribution Focal Lossï¼‰
        return v8.detect.DetectionValidator(self.test_loader, save_dir=self.save_dir, args=copy(self.args)) # DetectionValidatorï¼šå°è£…è¯„ä¼° (mAP50-95, precision, recall, speed metrics)ï¼›æ¥æ”¶ test_loader ä¸é…ç½®ï¼›ä½¿ç”¨ copy(self.args) é¿å…ä¸‹æ¸¸ä¿®æ”¹å½±å“åŸ args

    def label_loss_items(self, loss_items=None, prefix='train'):
        """
        Returns a loss dict with labelled training loss items tensor
        """
        # Not needed for classification but necessary for segmentation & detection
        keys = [f'{prefix}/{x}' for x in self.loss_names]
        if loss_items is not None:
            loss_items = [round(float(x), 5) for x in loss_items]  # convert tensors to 5 decimal place floats
            return dict(zip(keys, loss_items))
        else:
            return keys

    def progress_string(self):
        """Returns a formatted string of training progress with epoch, GPU memory, loss, instances and size."""
        # æ ¼å¼åŒ–è¿›åº¦æ˜¾ç¤ºå­—ç¬¦ä¸²å¤´éƒ¨ï¼šåŒ…å« Epoch, GPU_mem, å„æŸå¤±å, Instances, Sizeã€‚ç”¨äºtqdmåŠ¨æ€è¿›åº¦æ¡è¾“å‡ºã€‚
        return ('\n' + '%11s' *
                (4 + len(self.loss_names))) % ('Epoch', 'GPU_mem', *self.loss_names, 'Instances', 'Size')

    def plot_training_samples(self, batch, ni):
        """Plots training samples with their annotations.
        images: batch['img']
        batch_idx: æ¯ä¸ªç›®æ ‡å®ä¾‹å¯¹åº”çš„å›¾åƒç´¢å¼•ï¼Œç”¨äºæŠŠ bboxes/cls æ˜ å°„å›å›¾åƒã€‚
        cls: squeeze(-1) å»æ‰æœ«å°¾ä¸€ç»´ï¼ˆç±»åˆ« shape é€šå¸¸ [N,1]ï¼‰ã€‚
        bboxes: è®­ç»ƒæ ‡ç­¾çš„å½’ä¸€åŒ–æˆ–ç»å¯¹åæ ‡ï¼ˆå‡½æ•°å†…éƒ¨ä¼šå¤„ç†ï¼‰ã€‚
        paths: åŸå§‹å›¾è·¯å¾„ï¼ˆå åŠ æ ‡é¢˜ï¼‰ã€‚
        fname: ä¿å­˜è·¯å¾„ train_batch{ni}.jpg
        on_plot: å›è°ƒï¼ˆå¯èƒ½ç”¨äºè‡ªå®šä¹‰ç”»æ¿æˆ– GUIï¼‰
        """
        plot_images(images=batch['img'],
                    batch_idx=batch['batch_idx'],
                    cls=batch['cls'].squeeze(-1),
                    bboxes=batch['bboxes'],
                    paths=batch['im_file'],
                    fname=self.save_dir / f'train_batch{ni}.jpg',
                    on_plot=self.on_plot)

    def plot_metrics(self):
        """Plots metrics from a CSV file."""
        # ç”Ÿæˆ results.pngï¼ˆå¸¸è§åŒ…å« box_loss/cls_loss/dfl_loss, lr, mAP, precision, recall ç­‰æ›²çº¿ï¼‰ã€‚åœ¨çº¯æ£€æµ‹ä»»åŠ¡é»˜è®¤æ— éœ€æ ‡è¯† segment/pose
        plot_results(file=self.csv, on_plot=self.on_plot)  # save results.png

    def plot_training_labels(self):
        """Create a labeled training plot of the YOLO model."""
        boxes = np.concatenate([lb['bboxes'] for lb in self.train_loader.dataset.labels], 0)
        cls = np.concatenate([lb['cls'] for lb in self.train_loader.dataset.labels], 0)
        # plot_labelsï¼šç»˜åˆ¶ï¼ˆ1ï¼‰ç±»åˆ«ç›´æ–¹å›¾ï¼Œï¼ˆ2ï¼‰å®½é«˜åˆ†å¸ƒï¼Œï¼ˆ3ï¼‰å®½é«˜æ¯”ï¼Œï¼ˆ4ï¼‰é¢ç§¯åˆ†å¸ƒç­‰ â†’ ç”¨äºæ•°æ®è´¨é‡ä¸åˆ†å¸ƒæ£€æŸ¥
        plot_labels(boxes, cls.squeeze(), names=self.data['names'], save_dir=self.save_dir, on_plot=self.on_plot)


def train(cfg=DEFAULT_CFG, use_python=False):
    """Train and optimize YOLO model given training data and device."""
    model = cfg.model or 'yolov8n.pt'
    data = cfg.data or 'coco128.yaml'  # or yolo.ClassificationDataset("mnist")
    device = cfg.device if cfg.device is not None else ''

    args = dict(model=model, data=data, device=device)
    if use_python:
        from ultralytics import YOLO
        YOLO(model).train(**args)
    else:
        trainer = DetectionTrainer(overrides=args)
        trainer.train()

"""
train() å…¥å£å®è§‚é¡ºåºï¼š

1. æ”¶é›†å‚æ•° (model é…ç½®/æƒé‡è·¯å¾„, data æ•°æ®é…ç½®, device)
2. æ„é€  DetectionTrainer(overrides=args)
3. BaseTrainer.init å†…éƒ¨åšï¼šè¯»å– data.yaml â†’ self.dataï¼›è§£æè¶…å‚ï¼›è®¾ç½®ä¿å­˜ç›®å½•ï¼›æ„å»ºæ¨¡å‹ (è°ƒç”¨å­ç±» get_model)ï¼›æ„å»ºä¼˜åŒ–å™¨ï¼›æ„å»º dataloader (è°ƒç”¨ get_dataloader)ï¼›å‡†å¤‡ EMAã€AMPã€å›è°ƒç­‰
4. è°ƒç”¨ trainer.train():
    - for epoch in range(epochs):
        - è®­ç»ƒå¾ªç¯ï¼šè¿­ä»£ train dataloader
            é¢„å¤„ç† batch (preprocess_batch)
            å‰å‘ + å¾—åˆ°æŸå¤±å‘é‡
            åå‘ä¼ æ’­ + æ›´æ–°ä¼˜åŒ–å™¨ + EMA
            ç´¯ç§¯ç»Ÿè®¡ï¼ˆloss_names æŒ‡å¯¼æ˜ å°„ï¼‰
        - éªŒè¯ï¼šè°ƒç”¨ get_validator() è¿”å›çš„ validatorï¼Œå¯¹ test_loader åšæ¨ç†ã€è®¡ç®— mAP ç­‰
        - è®°å½•/ç»˜å›¾ï¼šplot_training_samplesï¼ˆå¶å°”ï¼‰ã€plot_metricsï¼ˆæœ€ç»ˆæˆ–é—´éš”ï¼‰ã€plot_training_labelsï¼ˆé¦–è½®ï¼‰
        - ä¿å­˜æœ€ä¼˜/æœ€è¿‘æƒé‡
5. ç»“æŸï¼šresults.png + weights + æ—¥å¿— CSV
"""

if __name__ == '__main__':
    train()
