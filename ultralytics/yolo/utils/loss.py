# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import torch
import torch.nn as nn
import torch.nn.functional as F

# OKS_SIGMA: åœ¨å§¿æ€å…³é”®ç‚¹æŸå¤±ä¸­ç”¨æ¥å¯¹ä¸åŒå…³é”®ç‚¹åšä¸åŒå°ºåº¦æ•æ„Ÿæ€§æƒé‡ï¼ˆCOCO è¯„ä¼°ä¸­ä½¿ç”¨çš„ sigmaï¼‰
from ultralytics.yolo.utils.metrics import OKS_SIGMA

# è‹¥å¹²å·¥å…·å‡½æ•°ï¼šç”¨äº mask è£å‰ªã€åæ ‡äº’æ¢ã€assigner/anchor/è·ç¦»è®¡ç®—ç­‰
from ultralytics.yolo.utils.ops import crop_mask, xywh2xyxy, xyxy2xywh
from ultralytics.yolo.utils.tal import TaskAlignedAssigner, dist2bbox, make_anchors

from .metrics import bbox_iou
from .tal import bbox2dist


class VarifocalLoss(nn.Module):
    """
    Varifocal lossï¼š
    - è®ºæ–‡ï¼šVarifocal Loss (Zhang et al.)ï¼Œç”¨äºæ”¹è¿›æ£€æµ‹å™¨ä¸­ç½®ä¿¡åº¦ä¸ç±»åˆ«å¾—åˆ†çš„è®­ç»ƒç›®æ ‡ã€‚
    - è®¾è®¡åŠ¨æœºï¼šè®©é«˜è´¨é‡ï¼ˆé«˜ IoUï¼‰çœŸé˜³æ€§å¾—åˆ°æ›´é«˜çš„è®­ç»ƒæƒé‡ï¼Œä»è€Œæå‡æ’åºä¸ç½®ä¿¡ä¼°è®¡è´¨é‡ã€‚
    - æœ¬å®ç°ï¼šå¯¹ BCEWithLogits ç»“æœä¹˜ä»¥ä¸€ä¸ªæƒé‡ï¼Œæƒé‡ç”±é¢„æµ‹æ¦‚ç‡ã€gt_scoreï¼ˆè´¨é‡è½¯æ ‡ç­¾ï¼‰å’Œ label å†³å®šã€‚
    """
    def __init__(self):
        super().__init__()

    def forward(self, pred_score, gt_score, label, alpha=0.75, gamma=2.0):
        """
        pred_score: logitsï¼ˆæœª sigmoidï¼‰
        gt_score: è½¯æ ‡ç­¾ï¼ˆä¾‹å¦‚ IoUï¼‰â€”â€”ç”¨äºå¯¹æ­£æ ·æœ¬åŠ æƒ
        label: 0/1 äºŒå€¼æ ‡ç­¾
        alpha/gamma: focal æ ·å¼çš„ç¼©æ”¾å‚æ•°
        è®¡ç®—æ­¥éª¤ï¼š
          weight = alpha * p^gamma * (1 - label) + gt_score * label
          loss = BCEWithLogits(pred_score, gt_score) * weight
        è¯´æ˜ï¼šå¯¹äºæ­£æ ·æœ¬ä½¿ç”¨ gt_score ç›´æ¥ä½œä¸ºæƒé‡ï¼›å¯¹è´Ÿæ ·æœ¬ä½¿ç”¨ç”±é¢„æµ‹æ¦‚ç‡è°ƒåˆ¶çš„æƒé‡ï¼ˆç±»ä¼¼ focalï¼‰ã€‚
        """
        weight = alpha * pred_score.sigmoid().pow(gamma) * (1 - label) + gt_score * label
        # åœ¨æ··åˆç²¾åº¦ä¸‹ç¡®ä¿ stableï¼ˆBCEWithLogits ç”¨ float32 æ›´ç¨³å®šï¼‰
        with torch.cuda.amp.autocast(enabled=False):
            loss = (F.binary_cross_entropy_with_logits(pred_score.float(), gt_score.float(), reduction='none') *
                    weight).mean(1).sum()
        return loss


class FocalLoss(nn.Module):
    """
    Focal loss wrapperï¼ˆç”¨äºäºŒåˆ†ç±» / æ¯-anchor å¤šç±»äºŒé€‰ä¸€åœºæ™¯ï¼‰ï¼š
    - åœ¨åŸå§‹ BCE ä¸Šä¹˜ä¸Š modulating factor (1 - p_t)^gamma æ¥é™ä½æ˜“åˆ†ç±»æ ·æœ¬çš„æƒé‡ã€‚
    - alpha ç”¨æ¥åšç±»åˆ«ä¸å¹³è¡¡çš„ re-weightã€‚
    """
    def __init__(self, ):
        super().__init__()

    def forward(self, pred, label, gamma=1.5, alpha=0.25):
        """
        pred: logits
        label: 0/1
        è¿”å›ï¼šå¯¹ batch çš„ sumï¼ˆæˆ–å¯æŒ‰éœ€è¦ meanï¼‰
        å®ç°é‡‡ç”¨ TF Addons å®ç°çš„è®¡ç®—æ–¹å¼ï¼ˆæ•°å€¼ç¨³å®šæ€§å¥½ï¼‰ã€‚
        """
        loss = F.binary_cross_entropy_with_logits(pred, label, reduction='none')
        pred_prob = pred.sigmoid()  # p
        p_t = label * pred_prob + (1 - label) * (1 - pred_prob)
        modulating_factor = (1.0 - p_t) ** gamma
        loss *= modulating_factor
        if alpha > 0:
            alpha_factor = label * alpha + (1 - label) * (1 - alpha)
            loss *= alpha_factor
        return loss.mean(1).sum()


class BboxLoss(nn.Module):
    """
    è¾¹ç•Œæ¡†æŸå¤±å®¹å™¨ï¼ˆIoU loss + å¯é€‰ DFLï¼‰:
    - IoU loss: ä½¿ç”¨ CIoUï¼ˆè€ƒè™‘ä¸­å¿ƒ/å°ºåº¦/çºµæ¨ªæ¯”ï¼‰ï¼Œè¡¡é‡é¢„æµ‹æ¡†ä¸ gt æ¡†çš„é‡åˆä¸å‡ ä½•å·®å¼‚ã€‚
    - DFL (Distribution Focal Loss): å°†è¾¹è·å›å½’è§†ä¸ºç¦»æ•£åˆ†å¸ƒå¹¶åšåˆ†ç±»å¼ lossï¼Œå†ç”¨æœŸæœ›æ¢å¤è¿ç»­å€¼ï¼Œæé«˜å®šä½ç²¾åº¦ã€‚
    - reg_max: æ§åˆ¶ç¦»æ•£åˆ†å¸ƒçš„ bin æ•°ï¼ˆreg_max + 1 ä¸ªç±»åˆ«ï¼‰
    å¯¹äºé¢„æµ‹æ£€æµ‹æ¡†ä¸­å¿ƒç‚¹æ‰€å±grid_cellè·ç¦»è¯¥grid_cellå·¦ä¸Šè§’ç‚¹çš„è·ç¦»æ—¶ï¼Œä¼šæ ¹æ®reg_maxè¿™ä¸ªå‚æ•°å°†è¯¥grid_cellçš„è¾¹åˆ’åˆ†ä¸º(reg_max + 1)ä¸ªbinï¼Œç„¶åé¢„æµ‹è¯¥ä¸­å¿ƒç‚¹åœ¨è¿™äº›binåŒºé—´çš„å–å€¼æ¦‚ç‡ï¼Œæœ€ç»ˆé€šè¿‡æ±‚æœŸæœ›çš„å½¢å¼æœ€ç»ˆç¡®å®šæ£€æµ‹æ¡†ä¸­å¿ƒç‚¹è·ç¦»grid_cellå·¦ä¸Šè§’ç‚¹çš„offset
    
    DFL çš„è®¾è®¡åŠ¨æœºï¼šè§£å†³ç¦»æ•£åŒ–åæ ‡çš„ç²¾åº¦æŸå¤±
    ä¼ ç»Ÿç›®æ ‡æ£€æµ‹ï¼ˆå¦‚ YOLOv5ï¼‰å¯¹è¾¹ç•Œæ¡†åæ ‡ï¼ˆå¦‚ä¸­å¿ƒç‚¹åç§»é‡ã€å®½é«˜ï¼‰çš„é¢„æµ‹é‡‡ç”¨ â€œç¦»æ•£åŒ–é”šç‚¹ + å›å½’ä¿®æ­£â€ ç­–ç•¥ï¼š
        - å°†åæ ‡èŒƒå›´åˆ’åˆ†ä¸ºè‹¥å¹²ç¦»æ•£åŒºé—´ï¼ˆå¦‚ 0~1 åˆ†ä¸º 10 ä¸ªåŒºé—´ï¼‰ï¼Œæ¨¡å‹é¢„æµ‹æ¯ä¸ªåŒºé—´çš„æ¦‚ç‡ï¼›
        - æœ€ç»ˆåæ ‡é€šè¿‡ â€œåŒºé—´ç´¢å¼• Ã— æ­¥é•¿ + åç§»é‡â€ è®¡ç®—ã€‚
    è¿™ç§æ–¹å¼å­˜åœ¨ç¼ºé™·ï¼š
        - ç¦»æ•£åŒºé—´åˆ’åˆ†å¯¼è‡´ â€œé‡åŒ–è¯¯å·®â€ï¼Œé¢„æµ‹åæ ‡éš¾ä»¥ç²¾ç¡®åŒ¹é…çœŸå®å€¼ï¼›
        - æ¨¡å‹ä»…è¾“å‡ºå•ä¸€åŒºé—´çš„æ¦‚ç‡ï¼Œå¿½ç•¥äº†ç›¸é‚»åŒºé—´çš„ç›¸å…³æ€§ï¼ˆå¦‚çœŸå®å€¼å¯èƒ½ä½äºä¸¤ä¸ªåŒºé—´çš„äº¤ç•Œå¤„ï¼‰ã€‚
    DFL é€šè¿‡å°†åæ ‡é¢„æµ‹è§†ä¸º â€œç¦»æ•£æ¦‚ç‡åˆ†å¸ƒâ€ï¼Œè®©æ¨¡å‹å­¦ä¹ åæ ‡åœ¨å„åŒºé—´çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå†é€šè¿‡åˆ†å¸ƒçš„ â€œæœŸæœ›â€ è®¡ç®—æœ€ç»ˆåæ ‡ï¼Œä»è€Œç¼“è§£é‡åŒ–è¯¯å·®ã€‚
    """
    def __init__(self, reg_max, use_dfl=False):
        super().__init__()
        self.reg_max = reg_max
        self.use_dfl = use_dfl

    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):
        """
        ä¸»è¦æ­¥éª¤ï¼š
        - å¯¹å‰æ™¯ï¼ˆfg_maskï¼‰æ ·æœ¬è®¡ç®—åŠ æƒ IoU æŸå¤±ï¼šloss_iou = sum((1 - IoU) * weight) / normalizer
        - å¦‚æœå¯ç”¨ DFL: è®¡ç®— pred_dist ä¸ target åˆ†å¸ƒçš„äº¤å‰ç†µæ’å€¼æŸå¤±å¹¶å½’ä¸€åŒ–
        å‚æ•°è¯´æ˜ï¼š
            pred_dist: ç½‘ç»œè¾“å‡ºçš„å›å½’åˆ†å¸ƒï¼ˆæˆ–ç›´æ¥å›å½’å€¼ï¼‰
            pred_bboxes: è§£ç å¾—åˆ°çš„é¢„æµ‹æ¡†ï¼ˆxyxyï¼‰
            anchor_points: æ¯ä¸ªé¢„æµ‹å¯¹åº”çš„ grid ä¸­å¿ƒç‚¹ï¼ˆç”¨äº bbox <-> dist çš„è½¬æ¢ï¼‰
            target_bboxes: åˆ†é…åˆ°æ­£æ ·æœ¬çš„ targetï¼ˆåœ¨ anchor/grid å‚è€ƒç³»ï¼‰
            target_scores: assigner ç»™å‡ºçš„åˆ†æ•°ï¼ˆè½¯æ ‡ç­¾ï¼‰
            target_scores_sum: æ­£æ ·æœ¬æ€»åˆ†ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
            fg_mask: å‰æ™¯æ©ç ï¼ˆå“ªäº›é¢„æµ‹è¢«è§†ä¸ºæ­£æ ·æœ¬ï¼‰
        è¿”å›: loss_iou, loss_dfl
        """
        # weight: å¯¹æ¯ä¸ªæ­£æ ·æœ¬æŒ‰ç…§ target_scores çš„å’Œæ¥åŠ æƒï¼ˆä½¿æ›´é«˜è´¨é‡æ ·æœ¬è´¡çŒ®æ›´å¤§ï¼‰
        weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)
        # CIoU è·ç¦»ï¼ˆè¶Šå¤§è¶Šå·®ï¼‰
        iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)
        loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum

        # è‹¥å¯ç”¨äº† DFLï¼Œåˆ™è®¡ç®— dfl æŸå¤±
        if self.use_dfl:
            # bbox2dist: æŠŠ gt bbox è½¬ä¸ºæ¯ä¸ªè¾¹ç•Œçš„ç¦»æ•£åˆ†å¸ƒç›®æ ‡
            target_ltrb = bbox2dist(anchor_points, target_bboxes, self.reg_max)
            loss_dfl = self._df_loss(pred_dist[fg_mask].view(-1, self.reg_max + 1), target_ltrb[fg_mask]) * weight
            loss_dfl = loss_dfl.sum() / target_scores_sum
        else:
            loss_dfl = torch.tensor(0.0).to(pred_dist.device)

        return loss_iou, loss_dfl

    @staticmethod
    def _df_loss(pred_dist, target):
        """
        Distribution Focal Loss (DFL):
        - å°† target è¡¨ç¤ºä¸ºå®æ•°ä½ç½®ï¼ˆéæ•´æ•° binï¼‰ï¼Œç”¨å·¦å³ä¸¤ä¸ªæ•´æ•° bin çš„äº¤å‰ç†µåŠ æƒé€¼è¿‘ï¼ˆçº¿æ€§æ’å€¼ï¼‰ã€‚
        - tl = floor(target), tr = tl + 1, weight = åˆ†åˆ«ä¸ºè·ç¦»æ¯”ä¾‹
        """
        tl = target.long()
        tr = tl + 1
        wl = tr - target
        wr = 1 - wl
        return (F.cross_entropy(pred_dist, tl.view(-1), reduction='none').view(tl.shape) * wl +
                F.cross_entropy(pred_dist, tr.view(-1), reduction='none').view(tl.shape) * wr).mean(-1, keepdim=True)


class KeypointLoss(nn.Module):
    """
    å…³é”®ç‚¹æ£€æµ‹çš„ç‰¹æ®Šæ€§å†³å®šäº† KeypointLoss ä¸èƒ½ç›´æ¥å¤ç”¨æ™®é€šå›å½’ä»»åŠ¡çš„æŸå¤±ï¼ˆå¦‚çº¯ MSEï¼‰ï¼Œéœ€è§£å†³ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
    - `åæ ‡å°ºåº¦ä¸€è‡´æ€§`ï¼šå…³é”®ç‚¹åæ ‡ä¾èµ–å›¾åƒåˆ†è¾¨ç‡ï¼ˆå¦‚ 640Ã—480 å›¾åƒä¸­ï¼Œx èŒƒå›´ 0-640ï¼Œy èŒƒå›´ 0-480ï¼‰ï¼Œéœ€é¿å…å°ºåº¦å·®å¼‚å¯¼è‡´æŸå¤±åå€šï¼›
    - `å¯è§æ€§å¤„ç†`ï¼šçœŸå®æ ‡æ³¨ä¸­å¸¸å­˜åœ¨ã€Œå…³é”®ç‚¹ä¸å¯è§ã€ï¼ˆå¦‚è¢«é®æŒ¡çš„æ‰‹è‚˜ï¼‰ï¼Œè‹¥å°†ä¸å¯è§å…³é”®ç‚¹è®¡å…¥æŸå¤±ï¼Œä¼šè¯¯å¯¼æ¨¡å‹å­¦ä¹ é”™è¯¯ä¿¡å·ï¼›
    - `å…³é”®ç‚¹é‡è¦æ€§å·®å¼‚`ï¼šä¸åŒå…³é”®ç‚¹çš„è¯­ä¹‰é‡è¦æ€§ä¸åŒï¼ˆå¦‚äººè„¸ä¸­ â€œçœ¼ç›â€ æ¯” â€œè„¸é¢Šâ€ æ›´é‡è¦ï¼‰ï¼Œéœ€æ”¯æŒå¯¹å…³é”®ç‚¹ä½èµ‹äºˆæ›´é«˜æƒé‡ã€‚
    
    åŸºäºä»¥ä¸Šé—®é¢˜ï¼ŒKeypointLoss çš„æ ¸å¿ƒè®¾è®¡åŸç†å¯æ¦‚æ‹¬ä¸ºï¼š
    ä»¥ã€Œåæ ‡å›å½’æŸå¤±ã€ä¸ºåŸºç¡€ï¼Œé€šè¿‡ã€Œå¯è§æ€§æ©ç ã€è¿‡æ»¤æ— æ•ˆæ ‡æ³¨ï¼Œé€šè¿‡ã€Œæƒé‡æœºåˆ¶ã€åŒºåˆ†å…³é”®ç‚¹é‡è¦æ€§ï¼Œæœ€ç»ˆå®ç°ç²¾å‡†ä¸”é²æ£’çš„å…³é”®ç‚¹å®šä½ä¼˜åŒ–ã€‚

    
    å§¿æ€å…³é”®ç‚¹ä½ç½®æŸå¤±ï¼š
    - ä½¿ç”¨æ¬§å¼è·ç¦»å¹¶ç»“åˆ OKS é£æ ¼çš„ sigma å’Œç›®æ ‡é¢ç§¯åšå½’ä¸€åŒ–ï¼Œ
      é‡‡ç”¨ (1 - exp(-e)) å½¢å¼é™ä½æç«¯è·ç¦»å½±å“ï¼ˆå‚è€ƒ COCO/OKS å…¬å¼ï¼‰ã€‚
    """
    def __init__(self, sigmas) -> None:
        super().__init__()
        self.sigmas = sigmas

    def forward(self, pred_kpts, gt_kpts, kpt_mask, area):
        """
        pred_kpts: (n, k, 2) æˆ– (n, k, 3)ï¼ˆè‹¥åŒ…å«å¯è§æ€§/ç½®ä¿¡ï¼‰
            - nï¼šæ­£æ ·æœ¬æ•°é‡ï¼ˆå¦‚å‰æ™¯é”šç‚¹ä¸ªæ•°ï¼‰
            - kï¼šå…³é”®ç‚¹æ•°é‡ï¼ˆå¦‚ COCOæ•°æ®é›†äººä½“çš„17ä¸ªå…³é”®ç‚¹ï¼‰
            - 2ï¼š(x, y) åæ ‡ï¼›3ï¼šé¢å¤–åŒ…å«å¯è§æ€§ç½®ä¿¡åº¦
        gt_kpts: (n, k, 3) - æœ€åä¸€ä¸ªç»´åº¦é€šå¸¸ä¸º (x, y, v)
        kpt_mask: ç”¨äºå¯è§æ€§å¤„ç†ã€‚(n, k) éé›¶è¡¨ç¤ºè¯¥ç‚¹å­˜åœ¨/æ ‡æ³¨ã€‚äºŒå€¼æ©ç ï¼Œéé›¶å€¼è¡¨ç¤ºè¯¥å…³é”®ç‚¹ã€Œæœ‰æ•ˆ / å¯è§ã€ï¼Œé›¶å€¼è¡¨ç¤ºæ— æ•ˆ
        area: æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº”çš„ç›®æ ‡é¢ç§¯ï¼ˆå¦‚è¾¹ç•Œæ¡†é¢ç§¯ï¼‰ï¼Œç”¨äºä¿è¯åæ ‡å°ºåº¦ä¸€è‡´æ€§
        è¿”å›å½’ä¸€åçš„å…³é”®ç‚¹æŸå¤±ï¼ˆæ ‡é‡ï¼‰
        """
        # è®¡ç®—é¢„æµ‹ä¸çœŸå®å…³é”®ç‚¹çš„ã€Œæ¬§æ°è·ç¦»çš„å¹³æ–¹ã€ï¼ˆx åæ ‡å·®çš„å¹³æ–¹ + y åæ ‡å·®çš„å¹³æ–¹ï¼‰
        """
        ... ç”¨äº çœç•¥å¼ é‡å‰é¢çš„æ‰€æœ‰ â€œéç›®æ ‡ç»´åº¦â€ï¼Œä»…ä¿ç•™æœ€åä¸€ä¸ªç»´åº¦ç”¨äºç´¢å¼•ã€‚å®ƒç­‰ä»·äº â€œå°†å‰é¢æ‰€æœ‰ç»´åº¦ç›´æ¥ä¼ é€’ï¼Œåªå¯¹æœ€åä¸€ç»´åšåˆ‡ç‰‡â€
        - pred_kpts[..., 0]ï¼šçœç•¥å‰ä¸¤ç»´ï¼ˆn, kï¼‰ï¼Œå–æœ€åä¸€ç»´çš„ç¬¬ 0 ä¸ªå…ƒç´  â†’ æå–æ‰€æœ‰æ­£æ ·æœ¬ã€æ‰€æœ‰å…³é”®ç‚¹çš„ x åæ ‡ï¼Œæœ€ç»ˆå½¢çŠ¶ä¸º (n, k)
        - pred_kpts[..., 1]ï¼šçœç•¥å‰ä¸¤ç»´ï¼ˆn, kï¼‰ï¼Œå–æœ€åä¸€ç»´çš„ç¬¬ 1 ä¸ªå…ƒç´  â†’ æå–æ‰€æœ‰æ­£æ ·æœ¬ã€æ‰€æœ‰å…³é”®ç‚¹çš„ y åæ ‡ï¼Œæœ€ç»ˆå½¢çŠ¶ä¸º (n, k)
        - gt_kpts[..., 0]ï¼šåŒç†ï¼Œä» (n, k, 3) ä¸­æå–æ‰€æœ‰æ­£æ ·æœ¬ã€æ‰€æœ‰å…³é”®ç‚¹çš„ çœŸå® x åæ ‡ï¼Œå½¢çŠ¶ (n, k)
        - gt_kpts[..., 1]ï¼šæå–æ‰€æœ‰æ­£æ ·æœ¬ã€æ‰€æœ‰å…³é”®ç‚¹çš„ çœŸå® y åæ ‡ï¼Œå½¢çŠ¶ (n, k)
        """
        d = (pred_kpts[..., 0] - gt_kpts[..., 0]) ** 2 + (pred_kpts[..., 1] - gt_kpts[..., 1]) ** 2 # ... ç”¨äºâ€œå°†å‰é¢æ‰€æœ‰ç»´åº¦ç›´æ¥ä¼ é€’ï¼Œåªå¯¹æœ€åä¸€ç»´åšåˆ‡ç‰‡â€ã€‚
        # loss factor é˜²æ­¢æ²¡æœ‰å…³é”®ç‚¹æ—¶æ¢¯åº¦ä¸º 0ï¼ˆä¿éšœæ•°å€¼ç¨³å®šæ€§ï¼‰
        kpt_loss_factor = (torch.sum(kpt_mask != 0) + torch.sum(kpt_mask == 0)) / (torch.sum(kpt_mask != 0) + 1e-9)
        # e = d / (2 * (area * sigma)^2) å‚è€ƒ COCO OKSï¼ˆæ­¤å¤„å®ç°ä¸ COCO è¯„ä¼°æ¥è¿‘ï¼‰
        e = d / (2 * self.sigmas) ** 2 / (area + 1e-9) / 2
        return kpt_loss_factor * ((1 - torch.exp(-e)) * kpt_mask).mean()


# ============================
# v8DetectionLossï¼šæ£€æµ‹ä»»åŠ¡çš„æ ¸å¿ƒæŸå¤±å®ç°ï¼ˆæ‰€æœ‰ task-specific loss éƒ½åŸºäºæ­¤æ„å»ºï¼‰
# ============================
class v8DetectionLoss:
    """
    è®¾è®¡ç†å¿µæ¦‚è¿°ï¼š
    - å°†æ£€æµ‹å…±æœ‰çš„æ­¥éª¤é›†ä¸­å®ç°ï¼špred è§£ç ï¼ˆåŒ…æ‹¬ DFL æ”¯æŒï¼‰ã€ç”Ÿæˆ anchorsã€ä½¿ç”¨ assigner åˆ†é…æ­£è´Ÿæ ·æœ¬ã€è®¡ç®— cls/bbox/dfl æŸå¤±ã€‚
        - å¤šå°ºåº¦ç‰¹å¾æ‹¼æ¥ï¼šæŠŠä¸åŒä¸‹é‡‡æ ·ç‡ï¼ˆstrideï¼‰çš„é¢„æµ‹åˆå¹¶æˆä¸€ä¸ªé•¿åˆ—è¡¨ï¼Œæ–¹ä¾¿ç»Ÿä¸€å¤„ç†ã€‚
        - è§£ç ï¼šæŠŠç½‘ç»œè¾“å‡ºçš„â€œå›å½’è¡¨è¾¾â€ï¼ˆå¯èƒ½æ˜¯åˆ†å¸ƒ/ç¦»æ•£ binï¼‰è½¬ä¸ºå®é™… bbox åæ ‡ï¼ˆxyxyï¼‰ã€‚
        - åˆ†é…ï¼šè®­ç»ƒæ—¶éœ€è¦çŸ¥é“å“ªäº›é¢„æµ‹ç‚¹æ˜¯æ­£æ ·æœ¬ï¼ˆè¦å¯¹å®ƒä»¬è®¡ç®— box/cat lossï¼‰ï¼Œå“ªäº›æ˜¯è´Ÿæ ·æœ¬ã€‚ä¼ ç»Ÿæ–¹æ³•ç”¨ anchor-IoU thresholdï¼Œä½†ç°ä»£æ–¹æ³•ï¼ˆTaskAligned/SimOTA ç­‰ï¼‰ä¼šç»¼åˆè€ƒè™‘ åˆ†ç±»ç½®ä¿¡åº¦ å’Œ bbox è´¨é‡ æ¥åŠ¨æ€é€‰æ­£æ ·æœ¬ï¼Œä»¥å¾—åˆ°æ›´å¯é çš„ç›‘ç£ä¿¡å·ã€‚
    - ä»»åŠ¡ç‰¹å¼‚æ€§ï¼ˆå¦‚ maskï¼kptï¼‰ç”±å­ç±»è¦†ç›– __call__ï¼ˆæˆ–åœ¨ __call__ ä¸­è°ƒç”¨çˆ¶ç±»å·¥å…·ï¼‰ã€‚
    """

    def __init__(self, model):  # model must be de-paralleled
        device = next(model.parameters()).device  # æ¨¡å‹å½“å‰ device
        h = model.args  # è¶…å‚æ•°ï¼ˆè®­ç»ƒè¶…å‚å­—å…¸ï¼‰

        m = model.model[-1]  # headï¼ˆDetect æ¨¡å—ï¼‰ï¼Œéœ€è¦è¯»å– head ä¸Šå®šä¹‰çš„ä¸€äº›å±æ€§
        self.bce = nn.BCEWithLogitsLoss(reduction='none')  # ç”¨äºæ¯-anchor æ¯-class çš„ BCEï¼ˆæœª reductionï¼‰
        self.hyp = h
        self.stride = m.stride  # head æ¯ä¸ªå°ºåº¦å¯¹åº”çš„ä¸‹é‡‡æ ·ç‡ï¼ˆtensorï¼‰
        self.nc = m.nc  # ç±»åˆ«æ•°é‡
        self.no = m.no  # head æ¯ä¸ªç½‘æ ¼ç‚¹è¾“å‡ºçš„é€šé“æ•°ï¼ˆreg+dimsï¼‰
        self.reg_max = m.reg_max  # ç”¨äº DFL çš„å‚æ•°
        self.device = device

        # æ˜¯å¦å¯ç”¨ DFLï¼ˆå½“ reg_max>1 æ—¶å¯ç”¨ï¼‰
        self.use_dfl = m.reg_max > 1

        # TaskAlignedAssignerï¼šä¸€ç§ç°ä»£çš„åˆ†é…å™¨ï¼Œç”¨äºåŠ¨æ€é€‰å–é«˜è´¨é‡é¢„æµ‹ä½œä¸ºæ­£æ ·æœ¬ï¼ˆç»“åˆ cls & iouï¼‰
        self.assigner = TaskAlignedAssigner(topk=10, num_classes=self.nc, alpha=0.5, beta=6.0)
        # bbox_loss å°è£… IoU + DFL è®¡ç®—
        self.bbox_loss = BboxLoss(m.reg_max - 1, use_dfl=self.use_dfl).to(device)
        # ç”¨äº DFL å°†ç¦»æ•£ bin ç¼–å· [0, 1, ..., reg_max-1] åš matmul è½¬ä¸ºæœŸæœ›
        self.proj = torch.arange(m.reg_max, dtype=torch.float, device=device)

    def preprocess(self, targets, batch_size, scale_tensor):
        """
        æŠŠ dataset æä¾›çš„ targetsï¼ˆæ¯è¡Œ: [img_idx, class, x,y,w,h]ï¼‰æŒ‰ image èšåˆæˆ (B, max_targets, 5)ï¼Œå¹¶æŠŠ xywh è½¬ä¸º xyxy å¹¶ä¹˜ scale_tensorï¼ˆæ¢å¤åƒç´ åæ ‡ï¼‰
        - å¹¶æŠŠ xywh è½¬ä¸º xyxy å¹¶ä¹˜ä»¥ scale_tensorï¼ˆæŠŠå½’ä¸€åŒ–åæ ‡æ¢å¤åˆ°åƒç´ å°ºåº¦ï¼‰ã€‚ä¸ºä»€ä¹ˆè¦è½¬æˆ xyxyï¼Ÿ å› ä¸ºæ¨¡å‹é¢„æµ‹çš„è¾¹ç•Œæ¡†è¾“å‡ºå°±æ˜¯ xyxy æ ¼å¼ï¼Œä¸”è®¡ç®—è¾¹ç•Œæ¡†æŸå¤±ï¼ˆå¦‚ CIoUï¼‰æ—¶ï¼Œéœ€è¦ç”¨ xyxy æ¥ç®—ä¸¤ä¸ªæ¡†çš„äº¤å¹¶æ¯”ã€ä¸­å¿ƒè·ç¦»ç­‰ï¼Œæ ¼å¼ä¸€è‡´æ‰èƒ½ç›´æ¥è®¡ç®—ã€‚
        - è¿™æ ·å¯ä»¥æŒ‰ image ç´¢å¼•å¯¹ targets åšæ‰¹å¤„ç†ï¼Œä¾¿äºåç»­ assign/è®¡ç®—
        - preprocessçš„è¾“å‡ºæ˜¯ä¸€ä¸ªæŒ‰å›¾ç‰‡åˆ†ç»„çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”æ‰¹æ¬¡ä¸­ä¸€å¼ å›¾ç‰‡çš„æ‰€æœ‰ç›®æ ‡æ ‡æ³¨ã€‚preprocessä¼šæ ¹æ®img_idxæŠŠæ ‡æ³¨æ‹†åˆ†æˆ â€œæ¯å¼ å›¾ä¸“å±çš„æ ‡æ³¨åˆ—è¡¨â€
        
        scale_tensorç”¨äºå°†å½’ä¸€åŒ–çš„æ ‡æ³¨æ•°æ®è½¬æ¢æˆâ€œåŸå›¾åƒç´ åæ ‡â€ã€‚åŸå§‹æ ‡æ³¨çš„x, y, w, hæ˜¯ â€œå½’ä¸€åŒ–å€¼â€ï¼ˆç›¸å¯¹äºåŸå›¾å®½é«˜ï¼‰ï¼Œè€Œæ¨¡å‹è¾“å…¥çš„å›¾ç‰‡å¯èƒ½ç»è¿‡äº†ç¼©æ”¾ï¼ˆæ¯”å¦‚åŸå›¾ 800x600â†’æ¨¡å‹è¾“å…¥ 640x480ï¼‰ï¼Œå› æ­¤éœ€è¦æŠŠå½’ä¸€åŒ–åæ ‡è½¬æ¢æˆ â€œè¾“å…¥å›¾åƒçš„åƒç´ åæ ‡â€
        
        out shape: (Batch_size, Max_target, 5), å…¶ä¸­ï¼Œmax_targets = å½“å‰ batch ä¸­å•å¼ å›¾ç‰‡çš„æœ€å¤§æ ‡æ³¨æ•°é‡ï¼›5 è¡¨ç¤º[class, x1, y1, x2, y2]ï¼Œå…¶ä¸­ x1,y1,x2,y2 æ˜¯ä»¥åƒç´ ä¸ºå•ä½çš„å·¦ä¸Š/å³ä¸‹è§’åæ ‡ï¼ˆxyxy å½¢å¼ï¼‰ï¼Œæ²¡æœ‰çœŸå® gt çš„å¡«å……è¡Œï¼Œå…¨ä¸º 0ï¼ˆå› æ­¤å¯ç”¨ sum == 0 åˆ¤æ–­è¿™ä¸€è¡Œæ˜¯ç©ºå¡«å……ï¼‰
        ä¾‹å¦‚å‡è®¾batch size = 8ï¼Œè¿™8å¼ å›¾ç‰‡ä¸­æ¯å¼ å›¾ç‰‡çš„Bboxæ ‡è®°æ•°é‡ä¸º3ï¼Œ 5ï¼Œ7ï¼Œ 9ï¼Œ 1ï¼Œ 2ï¼Œ2ï¼Œ 6.é‚£ä¹ˆMåº”è¯¥æ˜¯9ã€‚out ä¸­æ¯ä¸€è¡Œå‰ n=ç›®æ ‡æ•°é‡ä½ç½®å¡«çœŸå®å€¼ [class, x1,y1,x2,y2]ï¼ˆåƒç´ åæ ‡ï¼‰ï¼Œå‰©ä½™ä½ç½®å¡« 0
        """
        if targets.shape[0] == 0:
            out = torch.zeros(batch_size, 0, 5, device=self.device)
        else:
            i = targets[:, 0]  # image idx
            _, counts = i.unique(return_counts=True)
            counts = counts.to(dtype=torch.int32)
            out = torch.zeros(batch_size, counts.max(), 5, device=self.device)
            for j in range(batch_size):
                matches = i == j
                n = matches.sum()
                if n:
                    out[j, :n] = targets[matches, 1:]
            # targets[..., 1:5] åŸä¸º xywhï¼Œè½¬ä¸º xyxy å¹¶ä¹˜ä»¥ scaleï¼ˆæ¢å¤æˆåƒç´ ï¼‰
            out[..., 1:5] = xywh2xyxy(out[..., 1:5].mul_(scale_tensor))
        return out

    def bbox_decode(self, anchor_points, pred_dist):
        """
        å°†ç½‘ç»œé¢„æµ‹çš„å›å½’è¾“å‡ºè§£ç ä¸º bbox:
        - è‹¥å¯ç”¨ DFL: æŠŠ pred_dist reshape -> softmax on bins -> matmul proj -> å¾—åˆ°è¿ç»­å€¼
        - æœ€ç»ˆè°ƒç”¨ dist2bbox å°† ltrb distances ä¸ anchor_points è½¬ä¸º xyxy bbox
        """
        if self.use_dfl:
            b, a, c = pred_dist.shape  # batch, anchors, channels
            # è¿™é‡ŒæŠŠ channels -> 4 sides * (reg_max) æ¯ä¾§çš„åˆ†å¸ƒ
            pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))
            # pred_dist shape -> (b, a, 4)
        return dist2bbox(pred_dist, anchor_points, xywh=False)

    def __call__(self, preds, batch):
        """
        å¤„ç†é¢„æµ‹å¹¶è¿”å›æŸå¤±ï¼ˆsum across componentsï¼‰ï¼š
        preds: ç½‘ç»œè¾“å‡ºçš„ featsï¼ˆlist of feature mapsï¼‰æˆ– (feats, ...) å½¢å¼
        batch: æ¥è‡ª dataloader çš„ batchï¼ˆåŒ…å« batch_idx, cls, bboxes ç­‰ï¼‰
        é«˜å±‚æµç¨‹ï¼š
          - å°†å¤šå°ºåº¦ feat æ‹¼æ¥æˆ (B, no, Npred) å¹¶ split æˆ pred_distri & pred_scores
          - ç”Ÿæˆ anchor_points ä¸ stride_tensor
          - preprocess targets -> gt_labels / gt_bboxes
          - bbox_decode -> pred_bboxes
          - ä½¿ç”¨ assigner ç»™å‡ºæ­£æ ·æœ¬ mask/target_scores/target_bboxes
          - è®¡ç®— cls loss (BCE) ä¸ bbox loss (IoU + DFL)
          - æŒ‰è¶…å‚åŠ æƒè¿”å›æ€» loss
        """
        loss = torch.zeros(3, device=self.device)  # [box, cls, dfl]
        feats = preds[1] if isinstance(preds, tuple) else preds  # æ”¯æŒä¸¤ç§ preds ç»“æ„
        # å°† feats æ¯ä¸ªå°ºåº¦ reshape å¹¶åœ¨æœ€åç»´åº¦æ‹¼æ¥ï¼Œç„¶å split ä¸º (reg_dist, cls_logits)
        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(
            (self.reg_max * 4, self.nc), 1)

        # ä¸ºåç»­å¤„ç†è°ƒæ•´ç»´åº¦ (B, Npred, C)
        pred_scores = pred_scores.permute(0, 2, 1).contiguous()
        pred_distri = pred_distri.permute(0, 2, 1).contiguous()

        dtype = pred_scores.dtype
        batch_size = pred_scores.shape[0]
        # feats[0].shape[2:] æ˜¯æœ€å°å°ºåº¦çš„ç‰¹å¾å›¾ spatial sizeï¼Œä¹˜ä»¥ stride[0] å¾—åˆ° image size
        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]
        # ç”Ÿæˆ anchor grid ä¸­å¿ƒç‚¹ï¼ˆç›¸å¯¹äº feat gridï¼‰å’Œå¯¹åº” stride tensor
        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)

        # =========================
        # targets é¢„å¤„ç†
        # =========================
        targets = torch.cat((batch['batch_idx'].view(-1, 1), batch['cls'].view(-1, 1), batch['bboxes']), 1)
        targets = self.preprocess(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])
        gt_labels, gt_bboxes = targets.split((1, 4), 2)  # æ ‡ç­¾ä¸åæ ‡
        mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0)  # æ ‡æ³¨å­˜åœ¨çš„ mask

        # =========================
        # decode predicted bboxes
        # =========================
        pred_bboxes = self.bbox_decode(anchor_points, pred_distri)  # xyxy, shape (b, Npred, 4)

        # =========================
        # assigner: åˆ†é…æ­£è´Ÿæ ·æœ¬
        # =========================
        # assigner æ ¹æ®é¢„æµ‹åˆ†æ•°(sigmoid)ä¸é¢„æµ‹ bboxï¼ˆä¹˜å›åƒç´ å°ºåº¦ï¼‰ä¸ gt å»è®¡ç®—åŒ¹é…
        _, target_bboxes, target_scores, fg_mask, _ = self.assigner(
            pred_scores.detach().sigmoid(), (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),
            anchor_points * stride_tensor, gt_labels, gt_bboxes, mask_gt)

        target_scores_sum = max(target_scores.sum(), 1)

        # =========================
        # cls lossï¼ˆBCEï¼‰
        # =========================
        # æ³¨ï¼šå¯æ›¿æ¢ä¸º VarifocalLossï¼ˆæ›´å¤æ‚çš„ soft-label è®¾è®¡ï¼‰
        loss[1] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum

        # =========================
        # bbox lossï¼ˆIoU [+ DFL]ï¼‰
        # =========================
        if fg_mask.sum():
            target_bboxes /= stride_tensor  # å°† target box ä¹Ÿè½¬æ¢åˆ°ç½‘æ ¼å°ºåº¦
            loss[0], loss[2] = self.bbox_loss(pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores,
                                              target_scores_sum, fg_mask)

        # apply gains from hyperparameters
        loss[0] *= self.hyp.box
        loss[1] *= self.hyp.cls
        loss[2] *= self.hyp.dfl

        # è¿”å› scaled æ€» loss ä»¥åŠ detach çš„å„é¡¹ lossï¼ˆä¾¿äºæ—¥å¿—è®°å½•ï¼‰
        return loss.sum() * batch_size, loss.detach()


# ============================
# v8SegmentationLossï¼šåœ¨æ£€æµ‹ loss åŸºç¡€ä¸Šå¢åŠ  mask åˆ†æ”¯çš„æŸå¤±è®¡ç®—
# ============================
"""
v8SegmentationLossï¼ˆç»§æ‰¿ v8DetectionLoss å¹¶æ‰©å±•ï¼‰ åŠŸèƒ½ä¸è®¾è®¡ï¼š

- ç»§æ‰¿ v8DetectionLoss çš„å¤§éƒ¨åˆ†é€»è¾‘ï¼ˆbbox è§£ç ã€assignerã€cls lossã€bbox dflï¼‰ï¼Œæ–°å¢å¤„ç† mask åˆ†æ”¯çš„è®¡ç®—ã€‚
- é¢å¤–å±æ€§ï¼š
    - self.nmï¼šmask åŸå‹æ•°é‡ï¼ˆproto channelsï¼Œå…¸å‹ YOLACT é£æ ¼ï¼šproto æ˜¯ç½‘ç»œè¾“å‡ºçš„ä¸€ç»„åŸå‹ maskï¼‰ã€‚
    - self.overlapï¼šæ˜¯å¦é€šè¿‡ overlap_mask å¤„ç†é‡å  mask çš„é€»è¾‘ã€‚
- è¾“å…¥ predsï¼šç”± network è¿”å› (feats, pred_masks, proto)ï¼ˆæˆ–åŒ…å«åœ¨ tuple çš„ç¬¬äºŒå…ƒç´ ï¼‰ã€‚
    - proto æ˜¯ prototype mapsï¼ˆå½¢å¦‚ [B, nm, Hm, Wm]ï¼‰ã€‚
    - pred_masks æ˜¯æ¯ä¸ªé¢„æµ‹å¯¹åº”çš„ mask coefficientsï¼ˆæ¯ä¸ªé¢„æµ‹ä¼šçº¿æ€§ç»„åˆ proto å¾—åˆ°æœ€ç»ˆ maskï¼‰ã€‚
- å¯¹æ¯ä¸ªæ­£æ ·æœ¬ï¼š
    - ä» proto ä¸ pred_masks é€šè¿‡çº¿æ€§ç»„åˆå¾—åˆ° pred_maskï¼Œç„¶åç”¨ binary_cross_entropy_with_logits ä¸ gt_mask æ¯”è¾ƒã€‚
    - ä½¿ç”¨ crop_mask å°† mask è£å‰ªåˆ° bbox åŒºåŸŸå¹¶é™¤ä»¥åŒºåŸŸ areaï¼Œå‡å°å¤§ç›®æ ‡å¯¹æŸå¤±çš„ä¸»å¯¼å½±å“ï¼ˆnormalize by object areaï¼‰ã€‚
- ä¸ºé¿å… DDP ä¸­å‡ºç° unused gradients çš„é—®é¢˜ï¼Œä¿ç•™ä¸€äº›é›¶æ“ä½œã€‚
- æœ€ç»ˆ loss åŠ æƒï¼šbox, seg, cls, dfl åˆ†åˆ«ä¹˜ä»¥ self.hyp.box / box/batch / cls / dfl ç­‰ã€‚

ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼ˆç®—æ³•/å·¥ç¨‹åŸå› ï¼‰

- åˆ†å‰²ï¼ˆinstance maskï¼‰é€šå¸¸ç”¨ prototype+coeffsï¼ˆYOLACT æ ·å¼ï¼‰èƒ½é«˜æ•ˆåœ°äº§ç”Ÿä»»æ„æ•°é‡çš„ maskï¼Œè€Œä¸æ˜¯ä¸ºæ¯ä¸ªå®ä¾‹è¾“å‡ºå®Œæ•´ HxW maskã€‚
- ä¸ºäº†åŒæ—¶è®­ç»ƒæ£€æµ‹ä¸åˆ†å‰²ï¼Œloss éœ€è¦æ—¢ä¿è¯å®šä½/åˆ†ç±»ï¼Œåˆä¿è¯ mask è´¨é‡ï¼›å› æ­¤æŠŠ mask loss æ·»åŠ åˆ°æ£€æµ‹ loss ç®¡çº¿ä¸­å¹¶åšåˆé€‚çš„è§„èŒƒåŒ–ï¼ˆå¦‚æŒ‰é¢ç§¯ï¼‰ã€‚
- overlap é€‰é¡¹ç”¨äºå¤„ç†åŒä¸€åƒç´ å¯èƒ½å±äºå¤šä¸ªå®ä¾‹çš„æƒ…å†µï¼ˆéƒ¨åˆ†æ•°æ®é›†æ ‡ç­¾æ–¹å¼ä¸åŒï¼‰ã€‚
"""
class v8SegmentationLoss(v8DetectionLoss):
    """
    ç»§æ‰¿å…³ç³»ä¸è®¾è®¡ï¼š
    - ç»§æ‰¿ v8DetectionLossï¼Œå› æ­¤å¤ç”¨äº† detection çš„: å¤šå°ºåº¦ feat æ‹¼æ¥ã€decodeã€assignã€cls ä¸ bbox æŸå¤±è®¡ç®—
    - åœ¨æ­¤åŸºç¡€ä¸Šæ·»åŠ è¿˜åŸ/è®¡ç®— mask çš„æµç¨‹ï¼ˆPrototype mask + Coefficient çš„æ–¹å¼ï¼‰ï¼Œå¹¶æŠŠ mask æŸå¤±åŠ å…¥æ€»æŸå¤±ä¸­ã€‚
    è®¾è®¡åŠ¨æœºï¼š
    - ä½¿ç”¨ prototype + coeffsï¼ˆç±»ä¼¼ YOLACTï¼‰èƒ½èŠ‚çœæ˜¾å­˜ä¸è®¡ç®—ï¼šç½‘ç»œåªè¾“å‡ºå›ºå®šæ•°é‡çš„ proto ç‰¹å¾å›¾å’Œæ¯ä¸ªå®ä¾‹å¯¹åº”çš„ç³»æ•°ï¼Œ
      å†çº¿æ€§ç»„åˆå¾—åˆ°å®ä¾‹ maskã€‚
    - ProtoåŸå‹æ©ç ï¼šå…ˆå­¦ä¹ ä¸€ç»„é€šç”¨çš„â€œåŸå‹æ©ç â€ï¼Œå†ä¸ºæ¯ä¸ªç›®æ ‡é¢„æµ‹ä¸€ç»„â€œæƒé‡ç³»æ•°â€ï¼Œé€šè¿‡â€œç³»æ•°åŠ æƒåŸå‹â€çš„æ–¹å¼ç”Ÿæˆè¯¥ç›®æ ‡çš„ç‹¬ç‰¹æ©ç ï¼Œç”¨â€œå°‘é‡åŸºç¡€æ¨¡ç‰ˆâ€ç»„åˆå‡ºâ€œæ— é™ç»„ç›®æ ‡å½¢çŠ¶â€
    """
    def __init__(self, model):  # model must be de-paralleled
        super().__init__(model)
        self.nm = model.model[-1].nm  # head ä¸­å®šä¹‰çš„mask åŸå‹æ•°é‡ï¼ˆproto channelsï¼Œå…¸å‹ YOLACT é£æ ¼ï¼šproto æ˜¯ç½‘ç»œè¾“å‡ºçš„ä¸€ç»„åŸå‹ maskï¼‰ã€‚ 
        self.overlap = model.args.overlap_mask  # æ˜¯å¦æ ‡ç­¾ä¸­åŒåƒç´ å¯èƒ½å±äºå¤šä¸ªå®ä¾‹,æ˜¯å¦é€šè¿‡ overlap_mask å¤„ç†é‡å  mask çš„é€»è¾‘

    def __call__(self, preds, batch):
        """
        preds: (feats, pred_masks, proto) æˆ– (something, (feats, pred_masks, proto))
        - feats: list of feature maps for detection head
        - pred_masks: æ¯ä¸ªé¢„æµ‹å¯¹åº”çš„ mask coefficients (B, nm, Npred) -> ç»è¿‡ permute å (B, Npred, nm)
        - proto: prototype masks (B, nm, Hm, Wm) ç”¨äºçº¿æ€§ç»„åˆç”Ÿæˆæ¯ä¸ªå®ä¾‹çš„ mask
        æ€»ä½“æµç¨‹ï¼š
          - å…ˆå¤ç”¨ detection çš„ cls/bbox åˆ†æ”¯è®¡ç®—ï¼ˆåˆ©ç”¨ assigner å¾—åˆ° fg_maskã€target_idx ç­‰ï¼‰
          - å¯¹æ¯ä¸ªæ­£æ ·æœ¬æŒ‰ç´¢å¼•ç”¨ proto ä¸ coeff çº¿æ€§ç»„åˆé‡å»º pred_maskï¼Œå¹¶ä¸ gt_mask åš BCE æŸå¤±
          - mask æŸå¤±ä¼šæŒ‰ bbox é¢ç§¯å½’ä¸€ï¼ˆarea normalizationï¼‰å¹¶è£å‰ªåˆ° bboxï¼ˆcrop_maskï¼‰
        """
        loss = torch.zeros(4, device=self.device)  # box, seg, cls, dfl ï¼ˆæ³¨æ„ç´¢å¼•å¯¹åº”ï¼‰
        feats, pred_masks, proto = preds if len(preds) == 3 else preds[1] # è§£æè¾“å…¥ predsâ€”â€”preds ä¸º (feats, pred_masks, proto) æˆ–åµŒå¥— tupleï¼Œéœ€æå– featsï¼ˆæ£€æµ‹åˆ†æ”¯ç‰¹å¾å›¾ï¼‰ã€pred_masksï¼ˆmask ç³»æ•°ï¼‰ã€protoï¼ˆåŸå‹æ©ç ï¼‰
        batch_size, _, mask_h, mask_w = proto.shape  # proto çš„ç©ºé—´åˆ†è¾¨ç‡ï¼ˆé€šå¸¸æ¯”åŸå›¾ä½ï¼‰
        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(
            (self.reg_max * 4, self.nc), 1) # å¤„ç†å¤šå°ºåº¦ featsâ€”â€” å°†å„å°ºåº¦ feats æ‹¼æ¥å¹¶æ‹†åˆ†å¾—åˆ° pred_distriï¼ˆbbox å›å½’åˆ†å¸ƒï¼‰å’Œ pred_scoresï¼ˆåˆ†ç±»ç½®ä¿¡åº¦ï¼‰

        # å°† (B, no, N) -> (B, N, C), è°ƒæ•´ pred_masks çš„ç»´åº¦ï¼ˆä» (B, nm, Npred) è½¬ä¸º (B, Npred, nm)ï¼Œä¾¿äºåç»­æŒ‰å®ä¾‹è®¡ç®—ï¼‰
        pred_scores = pred_scores.permute(0, 2, 1).contiguous()
        pred_distri = pred_distri.permute(0, 2, 1).contiguous()
        # pred_masks: (B, nm, N) -> (B, N, nm)
        pred_masks = pred_masks.permute(0, 2, 1).contiguous()

        dtype = pred_scores.dtype
        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]
        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)

        # targets: ç±»ä¼¼ detection çš„å¤„ç†ï¼Œä½†è‹¥é segment æ•°æ®é›†ä¼šæŠ¥é”™ï¼ˆä¿æŠ¤æ€§æ£€æŸ¥ï¼‰
        try:
            batch_idx = batch['batch_idx'].view(-1, 1)
            targets = torch.cat((batch_idx, batch['cls'].view(-1, 1), batch['bboxes']), 1)
            targets = self.preprocess(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])
            gt_labels, gt_bboxes = targets.split((1, 4), 2)
            mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0)
        except RuntimeError as e:
            raise TypeError('ERROR âŒ segment dataset incorrectly formatted or not a segment dataset.\n'
                            "This error can occur when incorrectly training a 'segment' model on a 'detect' dataset, "
                            "i.e. 'yolo train model=yolov8n-seg.pt data=coco128.yaml'.\nVerify your dataset is a "
                            "correctly formatted 'segment' dataset using 'data=coco128-seg.yaml' "
                            'as an example.\nSee https://docs.ultralytics.com/tasks/segment/ for help.') from e

        # ç”Ÿæˆ anchors ä¸ bbox è§£ç  â€”â€” å¤ç”¨çˆ¶ç±» make_anchors ç”Ÿæˆ anchor_pointsï¼ˆç½‘æ ¼ä¸­å¿ƒç‚¹ï¼‰å’Œ stride_tensorï¼ˆå„ anchor çš„ä¸‹é‡‡æ ·ç‡ï¼‰ï¼Œè°ƒç”¨ bbox_decode å°† pred_distri è§£ç ä¸ºé¢„æµ‹ bboxï¼ˆxyxy æ ¼å¼ï¼‰
        pred_bboxes = self.bbox_decode(anchor_points, pred_distri)  # xyxy, (b, N, 4)

        # assigner: è¿”å› target_bboxes, target_scores, fg_mask, target_gt_idxï¼ˆåè€…ç”¨äºç´¢å¼• gt maskï¼‰
        """
        æ­£è´Ÿæ ·æœ¬åˆ†é…ï¼ˆassignerï¼‰ï¼š
        è°ƒç”¨ TaskAlignedAssignerï¼Œç»“åˆ pred_scoresï¼ˆsigmoid åï¼‰ã€pred_bboxesï¼ˆdetach åï¼‰ä¸ gt_labels/gt_bboxesï¼Œè¾“å‡º target_bboxesï¼ˆåˆ†é…çš„ gt bboxï¼‰ã€target_scoresï¼ˆåˆ†ç±»è½¯æ ‡ç­¾ï¼‰ã€fg_maskï¼ˆæ­£æ ·æœ¬æ©ç ï¼‰ã€target_gt_idxï¼ˆæ­£æ ·æœ¬å¯¹åº”çš„ gt ç´¢å¼•ï¼Œç”¨äºåç»­ç´¢å¼• gt_maskï¼‰ã€‚
        """
        _, target_bboxes, target_scores, fg_mask, target_gt_idx = self.assigner(
            pred_scores.detach().sigmoid(), (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),
            anchor_points * stride_tensor, gt_labels, gt_bboxes, mask_gt)

        target_scores_sum = max(target_scores.sum(), 1)

        # cls lossï¼ˆBCEï¼‰
        loss[2] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum

        if fg_mask.sum():
            # bbox lossï¼ˆIoU + DFLï¼‰
            loss[0], loss[3] = self.bbox_loss(pred_distri, pred_bboxes, anchor_points, target_bboxes / stride_tensor,
                                              target_scores, target_scores_sum, fg_mask)
            # masks loss è®¡ç®—
            masks = batch['masks'].to(self.device).float()
            # proto ä¸ gt_mask åˆ†è¾¨ç‡å¯¹é½ï¼šè‹¥ gt_maskï¼ˆbatch ['masks']ï¼‰çš„åˆ†è¾¨ç‡ä¸ proto ä¸ä¸€è‡´ï¼Œç”¨æœ€è¿‘é‚»æ’å€¼ä¸‹é‡‡æ ·åˆ° proto çš„åˆ†è¾¨ç‡ï¼ˆmask_h, mask_wï¼‰ï¼Œç¡®ä¿è®¡ç®—ç»´åº¦åŒ¹é…
            if tuple(masks.shape[-2:]) != (mask_h, mask_w):
                masks = F.interpolate(masks[None], (mask_h, mask_w), mode='nearest')[0]

            # å¯¹ batch ä¸­æ¯å¼ å›¾é€ä¸ªè®¡ç®—æ­£æ ·æœ¬å¯¹åº”çš„ mask lossï¼Œéå† batch é€å›¾å¤„ç†æ­£æ ·æœ¬
            for i in range(batch_size):
                if fg_mask[i].sum():
                    # target_gt_idx æŒ‡ç¤ºäº†æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº”çš„å“ªä¸ª gt mask ç´¢å¼•
                    mask_idx = target_gt_idx[i][fg_mask[i]]
                    if self.overlap: # ç´¢å¼• gt_maskï¼šæ ¹æ® target_gt_idx æ‰¾åˆ°å½“å‰æ­£æ ·æœ¬å¯¹åº”çš„ gt_maskï¼Œè‹¥ overlap=Trueï¼Œç”¨ torch.where å°† â€œåƒç´ å€¼ = å®ä¾‹ IDâ€ è½¬ä¸ºäºŒå€¼ maskï¼›å¦åˆ™ç›´æ¥æŒ‰ç´¢å¼•å– gt_mask
                        # è‹¥ dataset ç”¨é‡å  mask è¡¨ç¤ºä¸åŒå®ä¾‹å€¼ï¼ˆåƒç´ å€¼ä¸º instance idï¼‰ï¼Œåˆ™ç”¨ where æ„å»ºäºŒå€¼ gt_mask
                        gt_mask = torch.where(masks[[i]] == (mask_idx + 1).view(-1, 1, 1), 1.0, 0.0)
                    else:
                        gt_mask = masks[batch_idx.view(-1) == i][mask_idx]
                    # xyxy coords normalized in [0,1] ç”¨äº crop_maskï¼Œè®¡ç®— mask å½’ä¸€åŒ–å‚æ•°ï¼šå°† target_bboxes è½¬ä¸ºå½’ä¸€åŒ– xyxynï¼ˆç›¸å¯¹äºåŸå›¾ï¼‰ï¼Œå†è½¬ä¸º proto åˆ†è¾¨ç‡ä¸‹çš„ mxyxyï¼ˆç”¨äº crop_maskï¼‰ï¼Œè®¡ç®—ç›®æ ‡é¢ç§¯ mareaï¼ˆç”¨äºå¹³è¡¡å¤§å°ç›®æ ‡çš„ mask æŸå¤±ï¼‰
                    xyxyn = target_bboxes[i][fg_mask[i]] / imgsz[[1, 0, 1, 0]]
                    marea = xyxy2xywh(xyxyn)[:, 2:].prod(1)  # area normalization
                    mxyxy = xyxyn * torch.tensor([mask_w, mask_h, mask_w, mask_h], device=self.device)
                    # è°ƒç”¨ single_mask_loss è®¡ç®—å•å›¾æ­£æ ·æœ¬çš„ mask æŸå¤±ï¼Œå¹¶ç´¯åŠ åˆ°æ€» loss [1]ï¼ˆseg lossï¼‰ã€‚single_mask_loss: å°† pred coeff ä¸ proto çº¿æ€§ç»„åˆå¾—åˆ° pred_maskï¼Œå†ä¸ gt_mask è®¡ç®— BCEï¼Œå¹¶ crop/area normalization
                    loss[1] += self.single_mask_loss(gt_mask, pred_masks[i][fg_mask[i]], proto[i], mxyxy, marea)
                else:
                    # é˜²æ­¢ DDP ä¸­æŸäº›è¿›ç¨‹æ²¡æœ‰æ­£æ ·æœ¬å¯¼è‡´ unused-parameter çš„é—®é¢˜ï¼ˆä¿æŒæ¢¯åº¦å›¾è¿é€šï¼‰ã€‚DDP æ¢¯åº¦å›¾è¿é€šå¤„ç†ï¼šè‹¥æŸå›¾æ— æ­£æ ·æœ¬ï¼Œéœ€å¯¹ proto å’Œ pred_masks åš â€œ0 ä¹˜â€ æ“ä½œï¼ˆproto0 + pred_masks0ï¼‰ï¼Œé¿å… DDP è®­ç»ƒä¸­å› éƒ¨åˆ†è¿›ç¨‹æ— æ¢¯åº¦å¯¼è‡´çš„ unused params é”™è¯¯
                    loss[1] += (proto * 0).sum() + (pred_masks * 0).sum()
        else:
            # åŒä¸Šï¼šè‹¥æ•´ä¸ª batch æ²¡æœ‰æ­£æ ·æœ¬ï¼Œä¹Ÿä¿æŒæ¢¯åº¦å›¾è¿é€šä»¥é¿å… DDP æŠ¥é”™
            loss[1] += (proto * 0).sum() + (pred_masks * 0).sum()

        # loss æƒé‡
        # æŸå¤±åŠ æƒä¸è¿”å›ï¼šæŒ‰è¶…å‚ï¼ˆhypï¼‰å¯¹å„æŸå¤±é¡¹åŠ æƒï¼ˆbox -> hyp.boxã€seg -> hyp.box/batch_sizeã€cls -> hyp.clsã€dfl -> hyp.dflï¼‰ï¼Œè¿”å›æ€»æŸå¤±ï¼ˆä¹˜ä»¥ batch_size ä¿æŒå°ºåº¦ï¼‰å’Œå„åˆ†é¡¹æŸå¤±ï¼ˆdetach åç”¨äºæ—¥å¿—è®°å½•ï¼‰
        loss[0] *= self.hyp.box
        loss[1] *= self.hyp.box / batch_size  # seg loss é€šå¸¸æŒ‰ batch_size å½’ä¸€
        loss[2] *= self.hyp.cls
        loss[3] *= self.hyp.dfl

        # è¿”å›æ€» lossï¼ˆä¹˜ä»¥ batch_size ä»¥ä¿æŒå†å²å®ç°çš„ scaleï¼‰ä»¥åŠ detach çš„åˆ†é¡¹
        return loss.sum() * batch_size, loss.detach()

    def single_mask_loss(self, gt_mask, pred, proto, xyxy, area):
        """
        å•å®ä¾‹ mask lossï¼š
        - pred: è¯¥å®ä¾‹çš„ mask coefficient å‘é‡ (nm,)
        - proto: prototype maps (nm, Hm, Wm)
        - pred_mask = pred @ proto.reshape(nm, -1) -> reshape to (Hm, Wm)
        - ç”¨ BCEWithLogits ä¸ gt_mask è®¡ç®—åƒç´ çº§æŸå¤±ï¼Œç„¶å crop_maskï¼ˆåªè®¡ç®— bbox åŒºåŸŸï¼‰å¹¶æŒ‰ target é¢ç§¯å½’ä¸€
        è®¾è®¡ç†ç”±ï¼šæŒ‰é¢ç§¯å½’ä¸€å¯ä»¥å¹³è¡¡å¤§/å°å®ä¾‹çš„å½±å“ï¼ˆé¿å…å¤§å®ä¾‹ä¸»å¯¼ lossï¼‰
        """
        # ç”Ÿæˆé¢„æµ‹ maskï¼šå°† pred_masksï¼ˆå½“å‰å®ä¾‹çš„ç³»æ•°ï¼Œshape=(nm,)ï¼‰ä¸ protoï¼ˆshape=(nm, Hm, Wm)ï¼‰åšçŸ©é˜µä¹˜æ³•ï¼Œå³ pred_mask = pred @ proto.view (nm, -1)ï¼Œå† reshape ä¸º (n, Hm, Wm)ï¼ˆn ä¸ºå½“å‰å›¾æ­£æ ·æœ¬æ•°ï¼‰
        pred_mask = (pred @ proto.view(self.nm, -1)).view(-1, *proto.shape[1:])  # (n, Hm, Wm)
        # åƒç´ çº§æŸå¤±è®¡ç®—ï¼šç”¨ F.binary_cross_entropy_with_logits è®¡ç®— pred_mask ä¸ gt_mask çš„åƒç´ çº§ BCE æŸå¤±ï¼ˆreduction='none'ï¼Œä¿ç•™æ¯ä¸ªåƒç´ çš„æŸå¤±ï¼‰
        loss = F.binary_cross_entropy_with_logits(pred_mask, gt_mask, reduction='none')
        # è£å‰ªä¸å½’ä¸€ï¼šè°ƒç”¨ crop_mask è£å‰ªæ‰ mask ä¸­ â€œè¶…å‡ºç›®æ ‡ bboxâ€ çš„åŒºåŸŸï¼ˆåªä¿ç•™ç›®æ ‡åŒºåŸŸçš„æŸå¤±ï¼Œå‡å°‘èƒŒæ™¯å¹²æ‰°ï¼‰ï¼Œè®¡ç®—è£å‰ªåæŸå¤±çš„å‡å€¼ï¼Œå†é™¤ä»¥ç›®æ ‡é¢ç§¯ mareaï¼ˆå¹³è¡¡å¤§å°ç›®æ ‡çš„æŸå¤±è´¡çŒ®ï¼Œé¿å…å¤§ç›®æ ‡ä¸»å¯¼ lossï¼‰
        return (crop_mask(loss, xyxy).mean(dim=(1, 2)) / area).mean()


# ============================
# v8SegmentationPoseLossï¼šåœ¨ Segmentation åŸºç¡€ä¸Šè¿›ä¸€æ­¥åŠ å…¥å§¿æ€ï¼ˆå…³é”®ç‚¹ï¼‰æŸå¤±ï¼ˆè”åˆä»»åŠ¡ï¼‰
# ============================
"""
v8SegmentationPoseLoss
- ç»§æ‰¿è‡ª v8DetectionLossï¼Œç„¶ååŒæ—¶å®ç° segment çš„ mask loss å’Œ pose çš„å…³é”®ç‚¹ lossã€‚
- è¾“å…¥ preds åŒ…å« feats, pred_masks, proto, pred_kptsã€‚
- å¯¹æ¯ä¸ªæ­£æ ·æœ¬åŒæ—¶è®¡ç®— mask lossï¼ˆå’Œè£å‰ª/é¢ç§¯å½’ä¸€åŒ–ï¼‰ä¸å…³é”®ç‚¹ lossï¼ˆä½ç½® + å¯è§æ€§ï¼‰ï¼Œå†ä¸æ£€æµ‹ loss æƒé‡ç›¸åŠ ã€‚
- è®¾è®¡ç›®çš„æ˜¯åœ¨å•ä¸€ç½‘ç»œä¸­è”åˆå­¦ä¹  detection + segmentation + poseï¼Œåˆ©ç”¨å…±äº«ç‰¹å¾èŠ‚çº¦è®¡ç®—å¹¶è®©ä»»åŠ¡äº’ç›¸ç›‘ç£ï¼ˆä¾‹å¦‚å…³é”®ç‚¹å¯èƒ½å¢å¼ºå®ä¾‹è¾¹ç•Œç‰¹å¾ç­‰ï¼‰ã€‚

å®ç°ç»†èŠ‚ä¸å·¥ç¨‹æ³¨æ„ç‚¹ï¼ˆä¸ºä½•è¦è¿™æ ·å®ç°ï¼‰
- Permute/reshapeï¼šå¤šå°ºåº¦ feat çš„æ‹¼æ¥å’Œç»´åº¦å˜æ¢æ˜¯ä¸ºäº†æŠŠ (B, no, H, W) å½¢å¼è½¬æˆ (B, Npred, C) ä¾¿äºæ•´ä½“å¤„ç†ï¼ˆNpred = sum(HW)ï¼‰ã€‚
- make_anchorsï¼šè¿”å› anchor_pointsï¼ˆgrid çš„ä¸­å¿ƒç‚¹ç›¸å¯¹äº featureï¼‰ï¼Œä½¿ bbox è§£ç /å…³é”®ç‚¹è§£ç ä¸ç½‘ç»œç½‘æ ¼å¯¹é½ã€‚
- targets preprocessï¼šæŠŠ dataset ä¸­çš„ GT è½¬æˆç»Ÿä¸€ batch å½¢çŠ¶ï¼Œå¹¶ä¹˜ä»¥ scaleï¼ˆç”±ç½‘ç»œç‰¹å¾åˆ°åƒç´ å°ºåº¦çš„æ˜ å°„ï¼‰ä»¥ä¾¿åŒ¹é… decoded predictionsã€‚
- loss æƒé‡ï¼ˆself.hyp.xxxï¼‰ï¼šå¯è°ƒèŠ‚ä¸åŒä»»åŠ¡é‡è¦æ€§ï¼ˆä¾‹å¦‚ä½ å¯ä»¥æŠŠ pose çš„æƒé‡è°ƒé«˜ä»¥æå‡å…³é”®ç‚¹ç²¾åº¦ï¼‰ã€‚
- è¿”å›æ ¼å¼ï¼šloss.sum() * batch_sizeï¼ˆè®­ç»ƒä¸­å¸¸è¿™æ ·è¿”å›ä»¥ä¿æŒå’Œä»¥å‰å®ç°å…¼å®¹ï¼‰ï¼Œå¹¶è¿”å› detach çš„ loss components ä»¥ä¾¿åœ¨è®­ç»ƒæ—¥å¿—ä¸­æ˜¾ç¤ºã€‚
"""
class v8SegmentationPoseLoss(v8DetectionLoss):
    """
    è¿™ä¸ªç±»æ¼”åŒ–è‡ª v8DetectionLossï¼ˆå³ç»§æ‰¿ detection çš„æ ¸å¿ƒæµç¨‹ï¼‰ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šï¼š
      - å¼•å…¥ segmentation æ‰€éœ€çš„ proto/pred_masks/å•å®ä¾‹ mask lossï¼ˆå¤ç”¨ v8SegmentationLoss çš„æ€æƒ³ï¼‰
      - å¼•å…¥ pose æ‰€éœ€çš„ pred_kpts çš„è§£æä¸å…³é”®ç‚¹ lossï¼ˆKeypointLossï¼‰ã€å…³é”®ç‚¹å¯è§æ€§(kobj) loss
    è®¾è®¡åŠ¨æœºï¼š
      - å¤šä»»åŠ¡è”åˆè®­ç»ƒï¼ˆæ£€æµ‹ + åˆ†å‰² + å§¿æ€ï¼‰å¯ä»¥å…±äº« backbone/neck ç‰¹å¾ï¼Œäº’ç›¸ç›‘ç£æœ‰æ—¶èƒ½æå‡æ€§èƒ½ä¸”èŠ‚çœæ¨ç†æˆæœ¬ã€‚
      - ä½†å®ç°è¾ƒå¤æ‚ï¼šéœ€è¦åœ¨ assigner å¾—åˆ°æ­£æ ·æœ¬ç´¢å¼•ååŒæ—¶ä¸ºæ¯ä¸ªæ­£æ ·æœ¬è®¡ç®— mask loss ä¸ keypoint lossï¼Œå¹¶æ­£ç¡®å½’ä¸€åŒ–æƒé‡ã€‚
    å…³é”®ç‚¹ï¼ˆå®ç°ä¸Šéœ€è¦æ³¨æ„ï¼‰ï¼š
      - ç»§æ‰¿ v8DetectionLoss å¤ç”¨äº†ä»¥ä¸‹åŠŸèƒ½ï¼šanchors ç”Ÿæˆã€pred è§£ç ã€assigner è°ƒç”¨ã€bbox/cls/dfl åŸºæœ¬é¡¹ã€‚
      - ä¸º segmentation/p pose æ–°å¢çš„å­—æ®µä¸æ­¥éª¤éœ€ä¸ detection éƒ¨åˆ†å¯¹é½ï¼ˆä¾‹å¦‚ fg_mask, target_gt_idx ç”¨äºç´¢å¼• gt mask / keypointsï¼‰ã€‚
      - å…³é”®ç‚¹é¢„æµ‹ pred_kpts æ ¼å¼é¢„æœŸä¸º (B, nm?, Npred, kpt_shape) æˆ– (B, Npred, nkpt, 3)ï¼Œä»£ç å…ˆ permute -> reshape -> decodeã€‚
    """

    def __init__(self, model, overlap=True):  # model must be de-paralleled
        super().__init__(model)
        # mask prototype channels
        self.nm = model.model[-1].nm
        self.overlap = overlap

        # keypoints shape å­˜åœ¨äº head é…ç½®ä¸­ï¼ˆä¾‹å¦‚ [17, 3] è¡¨ç¤º 17 ä¸ªå…³é”®ç‚¹ï¼Œæ¯ä¸ªç‚¹é¢„æµ‹ (x,y,vis)ï¼‰
        self.kpt_shape = model.model[-1].kpt_shape
        # äºŒå€¼äº¤å‰ç”¨äº kpt å¯è§æ€§ / ç½®ä¿¡
        self.bce_pose = nn.BCEWithLogitsLoss()
        # è‹¥ kpt_shape == [17,3] åˆ™è®¤ä¸ºæ˜¯ COCO é£æ ¼ keypointsï¼Œä½¿ç”¨ OKS_SIGMA å¦åˆ™ç”¨å‡åŒ€æƒé‡
        is_pose = self.kpt_shape == [17, 3]
        nkpt = self.kpt_shape[0]
        sigmas = torch.from_numpy(OKS_SIGMA).to(self.device) if is_pose else torch.ones(nkpt, device=self.device) / nkpt
        # KeypointLoss ä¼šä½¿ç”¨ sigmas å’Œç›®æ ‡é¢ç§¯å¯¹å…³é”®ç‚¹è¯¯å·®åšåŠ æƒä¸å½’ä¸€
        self.keypoint_loss = KeypointLoss(sigmas=sigmas)

    def __call__(self, preds, batch):
        """
        preds: (feats, pred_masks, proto, pred_kpts) æˆ– preds[1] çš„å½¢å¼
        è¿”å›: æ€» lossï¼ŒåŠ detach çš„åˆ†é¡¹ï¼ˆbox, seg, cls, dfl, pose, kobjï¼‰
        ä¸»è¦æµç¨‹ï¼š
          1. å¤ç”¨ detection çš„ feat -> pred_distri / pred_scores è§£ç 
          2. permute/reshape pred_masks ä¸ pred_kptsï¼ˆä½¿å½¢çŠ¶ä¸º (B, Npred, nm) ä¸ (B, Npred, nkpt, kdim)ï¼‰
          3. ç”Ÿæˆ anchorsï¼Œpreprocess targetsï¼Œdecode pred_bboxes & pred_kptsï¼ˆkpts_decodeï¼‰
          4. ä½¿ç”¨ assigner åˆ†é…ï¼Œå¾—åˆ° fg_maskã€target_gt_idxï¼ˆåè€…ç”¨äºç´¢å¼• GT mask ä¸ GT keypointsï¼‰
          5. è®¡ç®— cls ä¸ bbox/dfl lossï¼ˆå¤ç”¨çˆ¶ç±»ï¼‰
          6. å¯¹æ¯ä¸ªæ­£æ ·æœ¬ï¼š
             - è®¡ç®— mask lossï¼ˆåŒ v8SegmentationLossï¼‰
             - æå–å¯¹åº” gt keypointsï¼ˆæŒ‰ anchor scale/stride è°ƒæ•´ï¼‰å¹¶è®¡ç®— keypoint_lossï¼ˆä½ç½®ï¼‰ä¸ kobjï¼ˆäºŒå€¼å¯è§æ€§ï¼‰æŸå¤±
          7. æŒ‰è¶…å‚å¯¹å„é¡¹ loss åŠ æƒå¹¶è¿”å›
        """
        loss = torch.zeros(6, device=self.device)  # box, seg, cls, dfl, pose, kobj
        feats, pred_masks, proto, pred_kpts = preds if len(preds) == 4 else preds[1]
        batch_size, _, mask_h, mask_w = proto.shape  # proto çš„ (B, nm, Hm, Wm)

        # å°† feats æ‹¼æ¥ä¸º pred_distri ä¸ pred_scoresï¼ˆç›¸åŒäºçˆ¶ç±»ï¼‰
        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(
            (self.reg_max * 4, self.nc), 1)
        # (B, no, N) -> (B, N, C)
        pred_scores = pred_scores.permute(0, 2, 1).contiguous()
        pred_distri = pred_distri.permute(0, 2, 1).contiguous()
        # pred_masks: (B, nm, N) -> (B, N, nm)
        pred_masks = pred_masks.permute(0, 2, 1).contiguous()
        # pred_kpts: (B, kdim, N) -> (B, N, kdim) -> ä¹‹åä¼š view æˆ (B, N, nkpt, kpt_dim)
        pred_kpts = pred_kpts.permute(0, 2, 1).contiguous()

        dtype = pred_scores.dtype
        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size in pixels
        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)

        # =========================
        # targets preprocessï¼ˆåŒ detectionï¼‰
        # =========================
        try:
            batch_idx = batch['batch_idx'].view(-1, 1)
            targets = torch.cat((batch_idx, batch['cls'].view(-1, 1), batch['bboxes']), 1)
            targets = self.preprocess(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])
            gt_labels, gt_bboxes = targets.split((1, 4), 2)
            mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0)
        except RuntimeError as e:
            raise TypeError('ERROR âŒ segment dataset incorrectly formatted or not a segment dataset.\n'
                            "This error can occur when incorrectly training a 'segment' model on a 'detect' dataset, "
                            "i.e. 'yolo train model=yolov8n-seg.pt data=coco128.yaml'.\nVerify your dataset is a "
                            "correctly formatted 'segment' dataset using 'data=coco128-seg.yaml' "
                            'as an example.\nSee https://docs.ultralytics.com/tasks/segment/ for help.') from e

        # =========================
        # decode predicted bboxes & keypoints
        # =========================
        pred_bboxes = self.bbox_decode(anchor_points, pred_distri)  # (B, N, 4)
        # pred_kpts éœ€è¦é‡å¡‘ä¸º (B, N, nkpt, kpt_dim) å† decode
        pred_kpts = self.kpts_decode(anchor_points, pred_kpts.view(batch_size, -1, *self.kpt_shape))  # (B, N, nkpt, kpt_dim)

        # assigner è¿”å› target_bboxes, target_scores, fg_mask, target_gt_idxï¼ˆtarget_gt_idx ç”¨äºç´¢å¼• GT mask/kptsï¼‰
        _, target_bboxes, target_scores, fg_mask, target_gt_idx = self.assigner(
            pred_scores.detach().sigmoid(), (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),
            anchor_points * stride_tensor, gt_labels, gt_bboxes, mask_gt)

        target_scores_sum = max(target_scores.sum(), 1)

        # cls loss
        loss[2] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum

        if fg_mask.sum():
            # bbox (IoU) å’Œ DFL lossï¼ˆå¤ç”¨ BboxLossï¼‰
            loss[0], loss[3] = self.bbox_loss(pred_distri, pred_bboxes, anchor_points, target_bboxes / stride_tensor,
                                              target_scores, target_scores_sum, fg_mask)
            # masks loss éƒ¨åˆ†ï¼ˆä¸ v8SegmentationLoss ç›¸åŒï¼‰
            masks = batch['masks'].to(self.device).float()
            if tuple(masks.shape[-2:]) != (mask_h, mask_w):
                masks = F.interpolate(masks[None], (mask_h, mask_w), mode='nearest')[0]

            # keypoints ä» batch ä¸­è¯»å…¥å¹¶æ”¾å¤§ä¸ºåƒç´ åæ ‡ï¼ˆä¹˜ä»¥ imgszï¼‰
            keypoints = batch['keypoints'].to(self.device).float().clone()
            keypoints[..., 0] *= imgsz[1]
            keypoints[..., 1] *= imgsz[0]

            # éå† batch ä¸­æ¯å¼ å›¾ï¼Œå¯¹å…¶æ­£æ ·æœ¬é€ä¸ªè®¡ç®— mask + keypoint loss
            for i in range(batch_size):
                if fg_mask[i].sum():
                    # ç”¨ assigner æä¾›çš„ target_gt_idx æ‰¾åˆ°å½“å‰æ­£æ ·æœ¬å¯¹åº”çš„ GT ç´¢å¼•
                    mask_idx = target_gt_idx[i][fg_mask[i]]
                    if self.overlap:
                        gt_mask = torch.where(masks[[i]] == (mask_idx + 1).view(-1, 1, 1), 1.0, 0.0)
                    else:
                        gt_mask = masks[batch_idx.view(-1) == i][mask_idx]
                    # å½’ä¸€åŒ– bbox åˆ° [0,1] ä»¥ä¾¿ crop_mask
                    xyxyn = target_bboxes[i][fg_mask[i]] / imgsz[[1, 0, 1, 0]]
                    marea = xyxy2xywh(xyxyn)[:, 2:].prod(1)  # é¢ç§¯
                    mxyxy = xyxyn * torch.tensor([mask_w, mask_h, mask_w, mask_h], device=self.device)
                    # mask loss ç´¯åŠ 
                    loss[1] += self.single_mask_loss(gt_mask, pred_masks[i][fg_mask[i]], proto[i], mxyxy, marea)

                    # ========== keypoint loss ==========
                    # æ ¹æ® assigner è¿”å›çš„ç´¢å¼•å–å‡ºå¯¹åº”çš„ GT keypointsï¼ˆå½¢çŠ¶ (n, nkpt, 3)ï¼‰
                    idx = target_gt_idx[i][fg_mask[i]]
                    gt_kpt = keypoints[batch_idx.view(-1) == i][idx]  # (n, nkpt, 3)
                    # æŠŠ gt_kpt çš„ xy æ¢ç®—æˆå’Œ pred_kpts ç›¸åŒçš„ç½‘æ ¼å°ºåº¦ï¼ˆé™¤ä»¥å¯¹åº”çš„ strideï¼‰
                    gt_kpt[..., 0] /= stride_tensor[fg_mask[i]]
                    gt_kpt[..., 1] /= stride_tensor[fg_mask[i]]
                    # area ç”¨äº keypoint loss å½’ä¸€ï¼ˆä½¿ç”¨ target_bboxes / stride_tensor å¾—åˆ°ç½‘æ ¼å°ºåº¦çš„ bboxï¼‰
                    area = xyxy2xywh((target_bboxes/stride_tensor)[i][fg_mask[i]])[:, 2:].prod(1, keepdim=True)
                    pred_kpt = pred_kpts[i][fg_mask[i]]  # predicted kpts for these positive anchors
                    # kpt_mask: å¯è§æ€§æ©ç ï¼ˆgt_kpt[...,2] != 0ï¼‰
                    kpt_mask = gt_kpt[..., 2] != 0
                    # ä½ç½®æŸå¤±ï¼ˆKeypointLossï¼‰
                    loss[4] += self.keypoint_loss(pred_kpt, gt_kpt, kpt_mask, area)
                    # è‹¥ pred_kpt åŒæ—¶è¾“å‡ºäº† kpt scoreï¼ˆæœ€åä¸€ç»´ == 3ï¼‰ï¼Œåˆ™è®¡ç®— kobj å¯è§æ€§/ç½®ä¿¡æŸå¤±ï¼ˆBCEï¼‰
                    if pred_kpt.shape[-1] == 3:
                        loss[5] += self.bce_pose(pred_kpt[..., 2], kpt_mask.float())

                else:
                    # ä¿æŒè®¡ç®—å›¾è¿é€šï¼Œé˜²æ­¢ DDP unused params
                    loss[1] += (proto * 0).sum() + (pred_masks * 0).sum()

        else:
            # åŒä¸Š
            loss[1] += (proto * 0).sum() + (pred_masks * 0).sum()

        # å½’ä¸€ä¸è¶…å‚åŠ æƒï¼š
        loss[0] *= self.hyp.box
        loss[1] *= self.hyp.box / batch_size  # seg æŒ‰ batch å½’ä¸€
        loss[2] *= self.hyp.cls
        loss[3] *= self.hyp.dfl
        loss[4] *= self.hyp.pose / batch_size  # pose ä½ç½®æŸå¤±æŒ‰ batch å½’ä¸€
        loss[5] *= self.hyp.kobj / batch_size  # kobj æŒ‰ batch å½’ä¸€

        return loss.sum() * batch_size, loss.detach()  # è¿”å›æ€» loss åŠå„åˆ†é¡¹ï¼ˆdetach ç”¨äºæ—¥å¿—ï¼‰

    def single_mask_loss(self, gt_mask, pred, proto, xyxy, area):
        """
        ä¸ v8SegmentationLoss.single_mask_loss ç›¸åŒå®ç°ï¼š
        - pred: (nm,) coefficient
        - proto: (nm, Hm, Wm)
        - pred_mask = pred @ proto.reshape(nm, -1) -> (Hm, Wm)
        - BCE + crop_mask + area å½’ä¸€
        """
        pred_mask = (pred @ proto.view(self.nm, -1)).view(-1, *proto.shape[1:])
        loss = F.binary_cross_entropy_with_logits(pred_mask, gt_mask, reduction='none')
        return (crop_mask(loss, xyxy).mean(dim=(1, 2)) / area).mean()

    def kpts_decode(self, anchor_points, pred_kpts):
        """
        æŠŠç›¸å¯¹é¢„æµ‹çš„å…³é”®ç‚¹å€¼è§£ç å› anchor/grid çš„åæ ‡ç³»ï¼š
        - pred_kpts çš„å‰ä¸¤ç»´å‡è®¾æ˜¯ç›¸å¯¹ offsetï¼ˆå®ç°ä¸Šä¹˜ 2 å†åç§» anchor-0.5ï¼Œå’Œ bbox offset çš„ç¼–ç ä¸€è‡´ï¼‰
        - è¿™ä¸€æ­¥ä¿è¯ pred_kpts ä¸ gt_kpt åœ¨åŒä¸€åæ ‡å°ºåº¦ä¸‹æ¯”è¾ƒï¼ˆç”¨äº KeypointLossï¼‰
        æ³¨æ„ï¼šè¯¥è§£ç å‡è®¾ç½‘ç»œè¾“å‡ºçš„ keypoint encoding æ˜¯æŒ‰ç›¸åŒçš„ç¼–ç è§„åˆ™ï¼ˆè§ç½‘ç»œ head å®ç°ï¼‰ã€‚
        """
        y = pred_kpts.clone()
        y[..., :2] *= 2.0
        y[..., 0] += anchor_points[:, [0]] - 0.5
        y[..., 1] += anchor_points[:, [1]] - 0.5
        return y


# ============================
# v8PoseLossï¼šåªåŒ…å«å§¿æ€ä»»åŠ¡ï¼ˆç»§æ‰¿è‡ª v8DetectionLossï¼‰
# v8SegmentationLoss ä¸ v8PoseLoss éƒ½æ˜¯åŸºäºç»Ÿä¸€çš„ detection æµç¨‹ï¼ˆmulti-scale concat â†’ decode â†’ assign â†’ cls/bbox lossï¼‰å†åˆ†åˆ«é™„åŠ ä»»åŠ¡ä¸“å±æ¨¡å—ï¼ˆprototype+coeff mask ä¸ keypoint decode+OKS lossï¼‰
# ============================
"""
v8PoseLossï¼ˆç»§æ‰¿ v8DetectionLoss å¹¶æ‰©å±•ï¼‰ åŠŸèƒ½ä¸è®¾è®¡è¦ç‚¹æ€»ç»“ï¼š
- åœ¨ç»§æ‰¿æ£€æµ‹é€šç”¨é€»è¾‘ï¼ˆmulti-scale concat / decode / assign / cls & bbox lossï¼‰çš„åŸºç¡€ä¸Šï¼Œæ–°å¢å…³é”®ç‚¹ä»»åŠ¡ç›¸å…³å¤„ç†ã€‚
- ç»§æ‰¿å¤ç”¨çš„é¡¹ç›®ï¼ˆæ¥è‡ªçˆ¶ç±» v8DetectionLossï¼‰ï¼š
    * å¤šå°ºåº¦ preds æ‹¼æ¥ã€pred_distri/pred_scores çš„ reshape/permute
    * anchor_points / stride_tensor çš„ç”Ÿæˆï¼ˆmake_anchorsï¼‰
    * targets preprocessï¼ˆç»Ÿä¸€æˆ (B, M, 5) æ ¼å¼ï¼‰
    * bbox è§£ç ï¼ˆåŒ…å« DFL æ”¯æŒï¼‰
    * assigner è°ƒç”¨ï¼ˆTaskAlignedAssignerï¼‰ç”¨äºç”Ÿæˆ fg_mask / target_scores / target_bboxes / target_gt_idx
    * bbox lossï¼ˆIoU + DFLï¼‰è®¡ç®—ï¼ˆBboxLossï¼‰
- æ–°å¢çš„ pose ç‰¹æ€§ï¼ˆv8PoseLoss ç‰¹æœ‰ï¼‰ï¼š
    * è§£æ pred_kptsï¼šæŠŠ head è¾“å‡ºçš„ pred_kpts reshape/permute ä¸º (B, Npred, nkpt, kpt_dim) å¹¶ decode åˆ° grid åæ ‡ï¼ˆkpts_decodeï¼‰
    * ä» batch ä¸­è¯»å– GT keypointsï¼ˆåƒç´ åæ ‡æˆ–å½’ä¸€åŒ–ï¼‰ï¼Œå°† GT è½¬æ¢åˆ° pred_kpts çš„åæ ‡å°ºåº¦ï¼ˆé€šå¸¸é™¤ä»¥ strideï¼‰ä»¥å¯¹é½
    * è®¡ç®— KeypointLossï¼ˆä½ç½®è¯¯å·®ï¼Œä½¿ç”¨ OKS sigma + area å½’ä¸€ï¼‰å’Œå¯è§æ€§/ç½®ä¿¡ BCEï¼ˆè‹¥æ¨¡å‹åŒæ—¶é¢„æµ‹å¯è§æ€§åˆ†é‡ï¼‰
- å·¥ç¨‹è®¾è®¡åŠ¨å› ï¼š
    * å¤šä»»åŠ¡å…±äº«ç‰¹å¾ï¼ˆbackbone/neckï¼‰å¯èŠ‚çœè®¡ç®—å¹¶æä¾›äº’è¡¥ç›‘ç£ï¼ˆä¾‹å¦‚å…³é”®ç‚¹å¯å¢å¼ºå®šä½ç‰¹å¾ï¼‰
    * ç»§æ‰¿çˆ¶ç±»å®ç°å¯é¿å…é‡å¤ä»£ç ä¸”ç¡®ä¿ assign / bbox loss çš„ä¸€è‡´æ€§ï¼ˆåŒä¸€ assign å®šä¹‰ç”¨äº detection ä¸ poseï¼‰
    * åœ¨æ­£æ ·æœ¬ï¼ˆfg_maskï¼‰ä¸Šè®¡ç®— pose lossï¼Œç¡®ä¿å…³é”®ç‚¹ supervision åªä½œç”¨äºä¸ GT åŒ¹é…çš„é¢„æµ‹ç‚¹ï¼ˆå³é‚£äº›è´Ÿè´£é¢„æµ‹è¯¥å®ä¾‹çš„ anchorsï¼‰
"""

class v8PoseLoss(v8DetectionLoss):
    """
    ç»§æ‰¿ v8DetectionLoss çš„é€šç”¨æ£€æµ‹é€»è¾‘ï¼Œå¹¶åœ¨å…¶ä¸Šæ·»åŠ  keypoint-specific lossï¼š
    - keypoint ä½ç½®æŸå¤±ï¼ˆKeypointLossï¼‰
    - keypoint å¯è§æ€§/ç½®ä¿¡æŸå¤±ï¼ˆBCEï¼‰
    è®¾è®¡ä¸ v8SegmentationPoseLoss çš„åŒºåˆ«åœ¨äºï¼šæ­¤ç±»åªå¤„ç† poseï¼ˆä¸å¤„ç† mask/protoï¼‰
    
    - â€œç»§æ‰¿â€æ„å‘³ç€ v8PoseLoss å¹¶æ²¡æœ‰é‡å†™ detection çš„å‰åŠéƒ¨åˆ†ï¼ˆæ‹¼æ¥/è§£ç /assignï¼‰ï¼Œ
      è€Œæ˜¯åœ¨é‚£äº›æ­¥éª¤ä¹‹åæ’å…¥ pose ç›¸å…³çš„å¤„ç†å¹¶å¤ç”¨ bbox/cls çš„æŸå¤±ç»“æœã€‚
    - è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼šä¿è¯ detection ä¸ pose ä½¿ç”¨ä¸€è‡´çš„æ­£æ ·æœ¬åˆ†é…ï¼ˆsame assignerï¼‰ï¼Œ
      ä½¿å¾— pose å­¦ä¹ ä¸æ£€æµ‹ä»»åŠ¡â€œå¯¹é½â€ï¼ˆé¿å…ä¸åŒä»»åŠ¡äº’ç›¸å†²çªï¼‰ã€‚
    """

    def __init__(self, model):  # model must be de-paralleled
        super().__init__(model) # ç»§æ‰¿çˆ¶ç±» v8DetectionLossï¼ˆç”±çˆ¶ç±»è·å¾—ï¼šself.bceã€self.strideã€self.ncã€self.noã€self.reg_maxã€self.assignerã€self.bbox_lossã€self.proj ç­‰æ£€æµ‹å…±ç”¨å·¥å…·ï¼‰
        self.kpt_shape = model.model[-1].kpt_shape # ä»æ¨¡å‹é…ç½®æ–‡ä»¶çš„headè¯»å–å…³é”®ç‚¹å‚æ•°
        self.bce_pose = nn.BCEWithLogitsLoss() # ç”¨äºå…³é”®ç‚¹çš„å¯è§æ€§/ç½®ä¿¡é¢„æµ‹æŸå¤±ï¼ˆbinary sigmoidsï¼‰Q: ä¸ºä»€ä¹ˆç”¨ BCE åš keypoint å¯è§æ€§è€Œä¸æ˜¯ MSEï¼ŸA: å¯è§æ€§/ç½®ä¿¡æ˜¯äºŒåˆ†ç±»/æ¦‚ç‡æ€§è´¨ï¼Œç”¨ BCEï¼ˆå¸¦ logitsï¼‰æ›´åˆé€‚ï¼›ä½ç½®ç”¨ä¸“é—¨å½’ä¸€åŒ–çš„æ¬§å¼/OKS é£æ ¼æŸå¤±ã€‚
        is_pose = self.kpt_shape == [17, 3] # COCO äººä½“å…³é”®ç‚¹ä»»åŠ¡çš„åˆ¤æ–­å¼€å…³ã€‚is_pose=Trueï¼šä½¿ç”¨ COCO é¢„å®šä¹‰çš„ OKS_SIGMAï¼›is_pose=Falseï¼šä½¿ç”¨é»˜è®¤çš„ â€œå‡åŒ€æƒé‡â€ï¼ˆtorch.ones(nkpt, device=self.device) / nkptï¼‰ï¼Œå³æ‰€æœ‰å…³é”®ç‚¹çš„è¯¯å·®æ•æ„Ÿåº¦ç›¸åŒ
        nkpt = self.kpt_shape[0]
        sigmas = torch.from_numpy(OKS_SIGMA).to(self.device) if is_pose else torch.ones(nkpt, device=self.device) / nkpt # OKSï¼ˆObject Keypoint Similarityï¼‰åœ¨ COCO ä¸­å®šä¹‰äº†ä¸åŒå…³é”®ç‚¹å¯¹è¯¯å·®çš„å°ºåº¦æ•æ„Ÿåº¦ï¼ˆä¾‹å¦‚é¼»å­æ¯”è„šæ›´ç²¾ç¡®é‡è¦ï¼‰ï¼Œè¯¥ sigma ç”¨äºæŒ‰å…³é”®ç‚¹ç±»å‹åŠ æƒä½ç½®è¯¯å·®ï¼Œä½¿è¯„ä»·ä¸è®­ç»ƒæ›´å¥‘åˆ COCO çš„å®é™…è¦æ±‚
        self.keypoint_loss = KeypointLoss(sigmas=sigmas) # KeypointLoss ä½¿ç”¨ sigmas ä¸ area åšå½’ä¸€

    def __call__(self, preds, batch):
        """
        preds: (feats, pred_kpts) æˆ– preds[1]
        ä¸»è¦æµç¨‹ï¼š
        1) å¤šå°ºåº¦ preds æ‹¼æ¥ -> å¾—åˆ° pred_distriï¼ˆå›å½’ï¼‰ä¸ pred_scoresï¼ˆåˆ†ç±»ï¼‰
        2) ç”Ÿæˆ anchor_points & stride_tensorï¼Œç”¨äº bbox ä¸ kpts çš„åæ ‡è§£ç ä¸å°ºåº¦è½¬æ¢
        3) preprocess batch targets -> gt_labels, gt_bboxesï¼ˆåƒç´ å°ºåº¦ï¼‰
        4) bbox_decode æŠŠ pred_distri è§£ç ä¸º pred_bboxesï¼ˆgrid å•ä½æˆ–æ¥è¿‘ï¼‰
        5) kpts_decode æŠŠ pred_kpts è§£ç ä¸º grid å•ä½çš„å…³é”®ç‚¹é¢„æµ‹ï¼ˆä»¥ anchor ä¸ºä¸­å¿ƒçš„åç§»ï¼‰
        6) assigner ä½¿ç”¨ pred_scores & pred_bboxes ä¸ GT åšåŒ¹é…ï¼Œå¾—åˆ° fg_mask ä¸ target_gt_idxï¼ˆåè€…ç”¨æ¥ç´¢å¼• GT keypointsï¼‰
        7) è®¡ç®— cls ä¸ bbox lossï¼ˆå¤ç”¨çˆ¶ç±»å®ç°ï¼‰
        8) å¯¹æ¯ä¸ªæ­£æ ·æœ¬ï¼Œå–å¯¹åº”çš„ gt_kptï¼ˆåƒç´ ï¼‰ï¼ŒæŠŠå®ƒè½¬ä¸º grid å•ä½ï¼ˆé™¤ä»¥ strideï¼‰ï¼Œè®¡ç®— keypoint lossï¼ˆä½ç½® + å¯è§æ€§ï¼‰
        """
        # é¢„åˆ†é… loss å‘é‡ï¼šç´¢å¼•å«ä¹‰åœ¨ä»£ç ä¸­æ³¨é‡Šæ˜ç¡®
        # loss indices mapping used here:
        # loss[0] = box (IoU)
        # loss[1] = kpt location loss
        # loss[2] = kpt visibility (kobj) BCE loss
        # loss[3] = cls loss
        # loss[4] = dfl loss (bbox distribution focal)   <-- æ³¨æ„ï¼šæ­¤å¤„çš„ç´¢å¼•é¡ºåºä¸ºå®ç°ç»†èŠ‚ï¼Œé˜…è¯»æ—¶ä»¥ä»£ç èµ‹å€¼ä¸ºå‡†
        loss = torch.zeros(5, device=self.device)  # box, cls, dfl, kpt_location, kpt_visibility
        feats, pred_kpts = preds if isinstance(preds[0], list) else preds[1] # preds è§£æï¼šæ”¯æŒä¸¤ç§ preds ç»“æ„ï¼ˆç›´æ¥ (feats, pred_kpts) æˆ– nestedï¼‰
        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(
            (self.reg_max * 4, self.nc), 1)

        # reshape ä¸º (B, Npred, C) ä»¥æ–¹ä¾¿åç»­è®¡ç®—
        pred_scores = pred_scores.permute(0, 2, 1).contiguous()
        pred_distri = pred_distri.permute(0, 2, 1).contiguous()
        # pred_kpts: (B, kdim, N) -> (B, N, kdim)
        pred_kpts = pred_kpts.permute(0, 2, 1).contiguous()

        dtype = pred_scores.dtype
        # è®¡ç®— image sizeï¼ˆåƒç´ ï¼‰ç”¨äºæŠŠå½’ä¸€åŒ– GT æ¢å¤ä¸ºåƒç´ åæ ‡
        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]
        # ç”Ÿæˆ anchorsï¼ˆgrid centersï¼‰ä¸ stride tensorï¼ˆæ¯ä¸ªé¢„æµ‹ç‚¹å¯¹åº”çš„ä¸‹é‡‡æ ·ç‡ï¼‰
        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)

        # =========================
        # targets preprocessï¼ˆåŒ detectionï¼‰
        # =========================
        batch_size = pred_scores.shape[0]
        batch_idx = batch['batch_idx'].view(-1, 1)
        targets = torch.cat((batch_idx, batch['cls'].view(-1, 1), batch['bboxes']), 1)
        targets = self.preprocess(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])
        gt_labels, gt_bboxes = targets.split((1, 4), 2)
        mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0)
        
        # =========================
        # decode boxes and kpts
        # =========================
        # pred_bboxes: (B, Npred, 4)ï¼ˆgrid å•ä½ / å¯ä¹˜ stride è¿˜åŸåˆ°åƒç´ ï¼‰
        pred_bboxes = self.bbox_decode(anchor_points, pred_distri)  # (B, N, 4)
        # pred_kpts éœ€è¦ view æˆ (B, Npred, nkpt, kpt_dim) å† decodeï¼ˆkpts_decode ä¼šæŠŠç›¸å¯¹ offset è½¬ä¸º grid åæ ‡ï¼‰
        pred_kpts = self.kpts_decode(anchor_points, pred_kpts.view(batch_size, -1, *self.kpt_shape))  # (B,N,nkpt,kpt_dim)

        # =========================
        # assigner: ä½¿ç”¨ pred_scores(sigmoid) ä¸ pred_bboxes*stride (åƒç´ å°ºåº¦) å»åŒ¹é… GT
        # è¿”å› (_, target_bboxes, target_scores, fg_mask, target_gt_idx)
        # target_gt_idx æ˜¯æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº”çš„ GT ç´¢å¼•ï¼Œç”¨äºåç»­ä» batch ä¸­å–å‡ºè¯¥å®ä¾‹çš„ keypoints
        _, target_bboxes, target_scores, fg_mask, target_gt_idx = self.assigner(
            pred_scores.detach().sigmoid(), (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),
            anchor_points * stride_tensor, gt_labels, gt_bboxes, mask_gt)

        target_scores_sum = max(target_scores.sum(), 1)

        # =========================
        # cls lossï¼ˆå¤ç”¨çˆ¶ç±» BCEï¼‰
        # =========================
        loss[3] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum

        # =========================
        # bbox + dfl + keypoint loss
        # =========================
        if fg_mask.sum():
            target_bboxes /= stride_tensor # å°† target_bboxes è½¬ä¸º grid å•ä½ï¼ˆä¸ pred_distri çš„åæ ‡ç³»ä¸€è‡´ï¼‰
            loss[0], loss[4] = self.bbox_loss(pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores,
                                              target_scores_sum, fg_mask) # bbox lossï¼ˆIoU, DFLï¼‰å¤ç”¨ BboxLoss
            # keypoints ä» batch ä¸­è¯»å–å¹¶å˜ä¸ºåƒç´ åæ ‡ï¼ˆå¦‚æœåŸå§‹æ˜¯å½’ä¸€åŒ–ï¼‰
            keypoints = batch['keypoints'].to(self.device).float().clone()
            keypoints[..., 0] *= imgsz[1] # x -> width
            keypoints[..., 1] *= imgsz[0] # y -> height
            
            # å¯¹æ¯å¼ å›¾ç‰‡å¤„ç†å…¶æ­£æ ·æœ¬
            for i in range(batch_size):
                if fg_mask[i].sum():
                    idx = target_gt_idx[i][fg_mask[i]] # target_gt_idx[i][fg_mask[i]] è¡¨ç¤ºå½“å‰å›¾ä¸­æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº”çš„ GT ç´¢å¼•
                    gt_kpt = keypoints[batch_idx.view(-1) == i][idx]  # æŒ‰ idx æå–è¯¥å›¾å¯¹åº” GT keypointsï¼ˆshape (n_pos, nkpt, 3)ï¼‰
                    # å½’ä¸€åŒ– gt_kpt åˆ°ç½‘æ ¼å°ºåº¦ï¼ŒæŠŠ GT é™¤ä»¥ strideï¼šé¢„æµ‹æ˜¯ä»¥ grid å•ä½æˆ–ç›¸å¯¹ anchor çš„åç§»ç¼–ç ï¼Œå¿…é¡»æŠŠ GT è½¬æ¢åˆ°ç›¸åŒå°ºåº¦æ‰èƒ½æ¯”è¾ƒ
                    # æŠŠ gt_kpt ä»åƒç´ åæ ‡è½¬æ¢ä¸ºä¸ pred_kpts ä¸€è‡´çš„ grid å•ä½ï¼ˆé™¤ä»¥ strideï¼‰
                    # æ³¨æ„ stride_tensor[fg_mask[i]] æ˜¯æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº”çš„ä¸‹é‡‡æ ·ç‡ï¼ˆåƒç´ ->gridï¼‰
                    gt_kpt[..., 0] /= stride_tensor[fg_mask[i]]
                    gt_kpt[..., 1] /= stride_tensor[fg_mask[i]]
                    # area: ä½¿ç”¨ target_bboxesï¼ˆå·²åœ¨ grid å•ä½ï¼‰è®¡ç®—ç›®æ ‡é¢ç§¯ï¼Œç”¨äº keypoint loss çš„å½’ä¸€
                    area = xyxy2xywh(target_bboxes[i][fg_mask[i]])[:, 2:].prod(1, keepdim=True)
                    # pred_kpt: (n_pos, nkpt, kpt_dim)ï¼Œå·²ç»è¿‡ kpts_decodeï¼Œå±äº grid å•ä½
                    pred_kpt = pred_kpts[i][fg_mask[i]]
                    kpt_mask = gt_kpt[..., 2] != 0 # è¿‡æ»¤æ‰ä¸å¯è§/æœªæ ‡æ³¨çš„å…³é”®ç‚¹ï¼Œé¿å…ç»™ä¸å¯è§ç‚¹æ–½åŠ é”™è¯¯ç›‘ç£
                    loss[1] += self.keypoint_loss(pred_kpt, gt_kpt, kpt_mask, area)  # kptä½ç½®æŸå¤±
                    # kpt å¯è§æ€§æŸå¤±,å¦‚æœæ¨¡å‹åŒæ—¶è¾“å‡ºå…³é”®ç‚¹ç½®ä¿¡åˆ†é‡ï¼ˆæœ€åä¸€ç»´ == 3ï¼‰ï¼Œç”¨ BCE å¯¹å¯è§æ€§/ç½®ä¿¡åšç›‘ç£
                    if pred_kpt.shape[-1] == 3:
                        loss[2] += self.bce_pose(pred_kpt[..., 2], kpt_mask.float())

        # apply gains
        loss[0] *= self.hyp.box
        loss[1] *= self.hyp.pose / batch_size
        loss[2] *= self.hyp.kobj / batch_size
        loss[3] *= self.hyp.cls
        loss[4] *= self.hyp.dfl

        # è¿”å› total lossï¼ˆä¹˜ä»¥ batch_size ä¿æŒåŸå®ç°æ¯”ä¾‹ï¼‰å’Œ detach çš„ loss itemsï¼ˆä¾¿äºæ—¥å¿—ï¼‰
        return loss.sum() * batch_size, loss.detach()

    def kpts_decode(self, anchor_points, pred_kpts):
        """
        æŠŠç½‘ç»œè¾“å‡ºçš„ç›¸å¯¹ kpt å€¼è§£ç åˆ° grid åæ ‡ã€‚
        ç»†èŠ‚è¯´æ˜ï¼ˆå°ç™½å‹å¥½ï¼‰ï¼š
        - ç½‘ç»œé€šå¸¸é¢„æµ‹ç›¸å¯¹äº anchor çš„åç§»ï¼ˆoffsetï¼‰ï¼Œå¸¸è§ç¼–ç ä¸ºå…ˆç¼©æ”¾ï¼ˆä¹˜ 2ï¼‰å†å¹³ç§» anchor-0.5ï¼š
            pred_decoded = pred_offset * 2 + anchor - 0.5
          è¿™ä¸ªç¼–ç åœ¨è®­ç»ƒä¸æ¨ç†æ—¶å¸¸è¢«ç”¨äºç¨³å®šæ•°å€¼ä¸çº¦æŸèŒƒå›´ï¼ˆæŠŠåç§»é™å®šåœ¨ [-0.5, 1.5] ç­‰å¯æ§åŒºé—´ï¼‰ã€‚
        - kpts_decode ä¼šæŠŠè¯¥åç§»è½¬æ¢ä¸ºä¸ anchor grid å¯¹é½çš„åæ ‡ï¼ˆgrid å•ä½ï¼‰ï¼Œä¾¿äºä¸æŠŠ GT é™¤ä»¥ stride åçš„åæ ‡ç›´æ¥æ¯”è¾ƒã€‚
        """
        y = pred_kpts.clone()
        y[..., :2] *= 2.0
        y[..., 0] += anchor_points[:, [0]] - 0.5
        y[..., 1] += anchor_points[:, [1]] - 0.5
        return y


class v8ClassificationLoss:
    """
    ç®€å•åˆ†ç±»æŸå¤±ï¼ˆcross_entropyï¼‰ï¼Œä¿ç•™ä¸å…¶ä»– loss é£æ ¼çš„ä¸€è‡´æ¥å£ï¼ˆè¿”å› loss ä¸ detach æ˜¾ç¤ºé¡¹ï¼‰
    """
    def __call__(self, preds, batch):
        loss = torch.nn.functional.cross_entropy(preds, batch['cls'], reduction='sum') / 64
        loss_items = loss.detach()